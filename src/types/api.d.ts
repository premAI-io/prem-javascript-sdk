/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */


/** OneOf type helpers */
type Without<T, U> = { [P in Exclude<keyof T, keyof U>]?: never };
type XOR<T, U> = (T | U) extends object ? (Without<T, U> & U) | (Without<U, T> & T) : T | U;
type OneOf<T extends any[]> = T extends [infer Only] ? Only : T extends [infer A, infer B, ...infer Rest] ? OneOf<[XOR<A, B>, ...Rest]> : never;

export interface paths {
  "/v1/chat/completions": {
    /** @description Creates a model response for the given chat conversation. Supports streaming with SSE, [documentation here](https://docs.premai.io/get-started/chat-completion-sse). */
    post: operations["v1_chat_completions_create"];
  };
  "/v1/embeddings": {
    /** @description Creates embeddings for the given input. */
    post: operations["v1_embeddings_create"];
  };
  "/v1/models/": {
    get: operations["v1_models_list"];
  };
  "/v1/models/{id}/": {
    get: operations["v1_models_retrieve"];
  };
  "/v1/repositories/": {
    post: operations["v1_repositories_create"];
  };
  "/v1/repository/{repository_id}/document": {
    post: operations["v1_repository_document_create"];
  };
  "/v1/set_trace_feedback": {
    /** @description Set trace feedback */
    post: operations["v1_set_trace_feedback_create"];
  };
  "/v1/traces/": {
    get: operations["v1_traces_list"];
  };
  "/v1/traces/{id}/": {
    get: operations["v1_traces_retrieve"];
  };
}

export type webhooks = Record<string, never>;

export interface components {
  schemas: {
    APIResponseValidationError: {
      message: string;
      /**
       * @description * `APIResponseValidationError` - APIResponseValidationError
       * @enum {string}
       */
      code: "APIResponseValidationError";
    };
    /**
     * @description * `APIResponseValidationError` - APIResponseValidationError
     * @enum {string}
     */
    APIResponseValidationErrorCodeEnum: "APIResponseValidationError";
    AuthenticationError: {
      message: string;
      /**
       * @description * `AuthenticationError` - AuthenticationError
       * @enum {string}
       */
      code: "AuthenticationError";
    };
    /**
     * @description * `AuthenticationError` - AuthenticationError
     * @enum {string}
     */
    AuthenticationErrorCodeEnum: "AuthenticationError";
    /** @enum {unknown} */
    BlankEnum: "";
    CatchAllError: {
      message: string;
      /**
       * @description * `CatchAllError` - CatchAllError
       * @enum {string}
       */
      code: "CatchAllError";
    };
    /**
     * @description * `CatchAllError` - CatchAllError
     * @enum {string}
     */
    CatchAllErrorCodeEnum: "CatchAllError";
    ChatCompletionInput: {
      /** @description The ID of the project to use. */
      project_id: number;
      /** @description The ID of the session to use. It helps to track the chat history. */
      session_id?: string;
      /** @description Options for Retrieval Augmented Generation (RAG). Will override launched model settings */
      repositories?: {
        /** @description The IDs of the repositories to use. */
        ids?: number[];
        limit?: number;
        /** Format: double */
        similarity_threshold?: number;
      };
      /** @description A list of messages comprising the conversation so far. */
      messages: ({
          /**
           * @description The role of the sender (e.g., 'user' or 'assistant').
           *
           * * `user` - user
           * * `assistant` - assistant
           */
          role: "user" | "assistant";
          /** @description The content of the message. */
          content?: string;
          /**
           * Format: uuid
           * @description The ID of the template to use.
           */
          template_id?: string;
          /** @description The parameters (key: value) to use with the given template. */
          params?: {
            [key: string]: unknown;
          };
        })[];
      /** @description ID of the model to use. See the model endpoint compatibility table for details. */
      model?: string;
      /** @description The system prompt to use. */
      system_prompt?: string;
      /** @description The maximum number of tokens to generate in the chat completion. */
      max_tokens?: number | null;
      /** @description If set, partial message deltas will be sent, like in ChatGPT. */
      stream?: boolean;
      /**
       * Format: double
       * @description What sampling temperature to use, between 0 and 2.
       * @default 1
       */
      temperature?: number;
      /** @description The tools to use in the completion. */
      tools?: {
          /**
           * @description * `function` - function
           * @enum {string}
           */
          type: "function";
          function: {
            name: string;
            description?: string;
            parameters: {
              type: string;
              properties: {
                [key: string]: {
                  type: string;
                  description: string;
                };
              };
              required: string[];
            };
          };
        }[] | null;
    };
    ChatCompletionResponse: {
      /** @description A list of chat completion choices. Can be more than one if n is greater than 1. */
      choices: ({
          /** @description The index of the choice in the list of choices. */
          index: number;
          /** @description The messages in the chat completion. */
          message: {
            /**
             * @description The role of the sender (e.g., 'user' or 'assistant').
             *
             * * `user` - user
             * * `assistant` - assistant
             */
            role: "user" | "assistant";
            /** @description The content of the message. */
            content?: string;
            /**
             * Format: uuid
             * @description The ID of the template to use.
             */
            template_id?: string;
            /** @description The parameters (key: value) to use with the given template. */
            params?: {
              [key: string]: unknown;
            };
          };
          /** @description The reason the chat completion finished, e.g., 'stop' or 'length'. */
          finish_reason: string;
          /** @description The tool calls made. */
          tool_calls?: {
              /**
               * Format: uuid
               * @description The ID of the tool call.
               */
              id: string;
              /** @description The function called. */
              function: {
                /** @description The name of the function to be called. */
                name: string;
                /** @description The arguments passed to the function. */
                arguments?: {
                  [key: string]: unknown;
                };
              };
              /** @description The type of tool call. */
              type: string;
            }[] | null;
        })[];
      /** @description The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp. */
      created: number;
      /** @description The model to generate the completion. */
      model: string;
      /** @description The name of the provider that generated the completion. */
      provider_name: string;
      /** @description The ID of the provider that generated the completion. */
      provider_id: string;
      /** @description Chunks used to improve the completion */
      document_chunks?: {
          repository_id?: number;
          document_id?: number;
          chunk_id?: number;
          document_name?: string;
          /** Format: double */
          similarity_score?: number;
          content?: string;
        }[];
      /** @description The usage statistics for the completion. */
      usage: {
        prompt_tokens: number;
        completion_tokens?: number;
        total_tokens: number;
      };
      /**
       * Format: uuid
       * @description The trace ID of the completion.
       */
      trace_id: string;
    };
    ConflictError: {
      message: string;
      /**
       * @description * `ConflictError` - ConflictError
       * @enum {string}
       */
      code: "ConflictError";
    };
    /**
     * @description * `ConflictError` - ConflictError
     * @enum {string}
     */
    ConflictErrorCodeEnum: "ConflictError";
    DocumentChunks: {
      repository_id?: number;
      document_id?: number;
      chunk_id?: number;
      document_name?: string;
      /** Format: double */
      similarity_score?: number;
      content?: string;
    };
    DocumentInput: {
      /** Format: uri */
      file: string;
    };
    DocumentOutput: {
      repository_id: number;
      document_id: number;
      name: string;
      /**
       * @description * `pdf` - PDF
       * * `docx` - Word
       * * `txt` - Text
       * @enum {string}
       */
      document_type: "pdf" | "docx" | "txt";
      /**
       * @description * `PENDING` - Pending
       * * `UPLOADED` - Uploaded
       * * `PARSING` - Parsing
       * * `CHUNKING` - Chunking
       * * `WAITING_FOR_CHUNKS_COMPLETION` - Waiting for chunks completion
       * * `PROCESSING` - Processing
       * * `COMPLETED` - Completed
       * * `FAILED` - Failed
       * @enum {string}
       */
      status: "PENDING" | "UPLOADED" | "PARSING" | "CHUNKING" | "WAITING_FOR_CHUNKS_COMPLETION" | "PROCESSING" | "COMPLETED" | "FAILED";
      error: string | null;
      /** @default 0 */
      chunk_count: number;
    };
    /**
     * @description * `pdf` - PDF
     * * `docx` - Word
     * * `txt` - Text
     * @enum {string}
     */
    DocumentTypeEnum: "pdf" | "docx" | "txt";
    Embedding: {
      /** @description The index of the token in the input. */
      index: number;
      /** @description The embedding for the input. */
      embedding: number[];
    };
    EmbeddingsInput: {
      /** @description The ID of the project to use. */
      project_id: number;
      /** @description The model to generate the embeddings. */
      model: string;
      /** @default float */
      encoding_format?: "float" | "base64";
      /** @description Embedding Input */
      input: string | string[] | number[] | number[][];
    };
    EmbeddingsResponse: {
      /** @description The embeddings for the input. */
      data: {
          /** @description The index of the token in the input. */
          index: number;
          /** @description The embedding for the input. */
          embedding: number[];
        }[];
      /** @description The model to generate the embeddings. */
      model: string;
      /** @description The usage statistics for the completion. */
      usage: {
        prompt_tokens: number;
        completion_tokens?: number;
        total_tokens: number;
      };
      /** @description The name of the provider that generated the completion. */
      provider_name: string;
      /** @description The ID of the provider that generated the completion. */
      provider_id: string;
    };
    /**
     * @description * `float` - float
     * * `base64` - base64
     * @enum {string}
     */
    EncodingFormatEnum: "float" | "base64";
    Enhancement: {
      /** @description The IDs of the repositories to use. */
      ids?: number[];
      limit?: number;
      /** Format: double */
      similarity_threshold?: number;
    };
    FeedbackCreate: {
      /** Format: uuid */
      trace_id: string;
      feedback?: ({
        /** @default false */
        positive?: boolean;
        messages?: ({
            /**
             * @description * `user` - user
             * * `assistant` - assistant
             * * `system` - system
             * @enum {string}
             */
            role?: "user" | "assistant" | "system";
            content?: string;
          })[];
      }) | null;
    };
    FeedbackCreateFeedback: {
      /** @default false */
      positive?: boolean;
      messages?: ({
          /**
           * @description * `user` - user
           * * `assistant` - assistant
           * * `system` - system
           * @enum {string}
           */
          role?: "user" | "assistant" | "system";
          content?: string;
        })[];
    };
    Function: {
      name: string;
      description?: string;
      parameters: {
        type: string;
        properties: {
          [key: string]: {
            type: string;
            description: string;
          };
        };
        required: string[];
      };
    };
    InternalServerError: {
      message: string;
      /**
       * @description * `ProviderInternalServerError` - ProviderInternalServerError
       * @enum {string}
       */
      code: "ProviderInternalServerError";
    } | {
      message: string;
      /**
       * @description * `APIResponseValidationError` - APIResponseValidationError
       * @enum {string}
       */
      code: "APIResponseValidationError";
    } | {
      message: string;
      /**
       * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
       * @enum {string}
       */
      code: "ProviderAPIStatusError";
    } | {
      message: string;
      /**
       * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
       * @enum {string}
       */
      code: "ProviderAPITimeoutError";
    } | {
      message: string;
      /**
       * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
       * @enum {string}
       */
      code: "ProviderAPIConnectionError";
    } | {
      message: string;
      /**
       * @description * `CatchAllError` - CatchAllError
       * @enum {string}
       */
      code: "CatchAllError";
    };
    Message: {
      /**
       * @description The role of the sender (e.g., 'user' or 'assistant').
       *
       * * `user` - user
       * * `assistant` - assistant
       */
      role: "user" | "assistant";
      /** @description The content of the message. */
      content?: string;
      /**
       * Format: uuid
       * @description The ID of the template to use.
       */
      template_id?: string;
      /** @description The parameters (key: value) to use with the given template. */
      params?: {
        [key: string]: unknown;
      };
    };
    /**
     * @description * `user` - user
     * * `assistant` - assistant
     * @enum {string}
     */
    MessageRoleEnum: "user" | "assistant";
    Messages: {
      /**
       * @description * `user` - user
       * * `assistant` - assistant
       * * `system` - system
       * @enum {string}
       */
      role?: "user" | "assistant" | "system";
      content?: string;
    };
    /**
     * @description * `user` - user
     * * `assistant` - assistant
     * * `system` - system
     * @enum {string}
     */
    MessagesRoleEnum: "user" | "assistant" | "system";
    Model: {
      id: number;
      name: string;
      /**
       * @description * `text2text` - Text to Text
       * * `text2image` - Text to Image
       * * `text2vector` - Text to Vector
       * * `autopilot` - Autopilot
       * @enum {string}
       */
      model_type?: "text2text" | "text2image" | "text2vector" | "autopilot";
      model_provider?: ("openai" | "azure" | "azure-mistral" | "cohere" | "anthropic" | "cloudflare" | "deepinfra" | "lamini" | "octoai" | "replicate" | "together" | "fireworksai" | "mistralai" | "prem" | "anyscale" | "openrouter" | "perplexity" | "groq") | "" | null;
      deprecated?: boolean;
    };
    ModelNotFoundError: {
      message: string;
      /**
       * @description * `ModelNotFoundError` - ModelNotFoundError
       * @enum {string}
       */
      code: "ModelNotFoundError";
    };
    /**
     * @description * `ModelNotFoundError` - ModelNotFoundError
     * @enum {string}
     */
    ModelNotFoundErrorCodeEnum: "ModelNotFoundError";
    /**
     * @description * `openai` - OpenAI
     * * `azure` - Azure OpenAI
     * * `azure-mistral` - Azure Mistral
     * * `cohere` - Cohere
     * * `anthropic` - Anthropic
     * * `cloudflare` - Cloudflare
     * * `deepinfra` - Deep Infra
     * * `lamini` - Lamini
     * * `octoai` - Octo AI
     * * `replicate` - Replicate
     * * `together` - Together
     * * `fireworksai` - Fireworks AI
     * * `mistralai` - Mistral AI
     * * `prem` - Prem AI
     * * `anyscale` - Anyscale
     * * `openrouter` - Open Router
     * * `perplexity` - Perplexity
     * * `groq` - Groq
     * @enum {string}
     */
    ModelProviderEnum: "openai" | "azure" | "azure-mistral" | "cohere" | "anthropic" | "cloudflare" | "deepinfra" | "lamini" | "octoai" | "replicate" | "together" | "fireworksai" | "mistralai" | "prem" | "anyscale" | "openrouter" | "perplexity" | "groq";
    /**
     * @description * `text2text` - Text to Text
     * * `text2image` - Text to Image
     * * `text2vector` - Text to Vector
     * * `autopilot` - Autopilot
     * @enum {string}
     */
    ModelTypeEnum: "text2text" | "text2image" | "text2vector" | "autopilot";
    NotFoundError: OneOf<[{
      message: string;
      /**
       * @description * `ProviderNotFoundError` - ProviderNotFoundError
       * @enum {string}
       */
      code: "ProviderNotFoundError";
    }, {
      message: string;
      /**
       * @description * `ModelNotFoundError` - ModelNotFoundError
       * @enum {string}
       */
      code: "ModelNotFoundError";
    }]>;
    /** @enum {unknown} */
    NullEnum: "";
    OutputFunction: {
      /** @description The name of the function to be called. */
      name: string;
      /** @description The arguments passed to the function. */
      arguments?: {
        [key: string]: unknown;
      };
    };
    ParameterProperties: {
      type: string;
      description: string;
    };
    Parameters: {
      type: string;
      properties: {
        [key: string]: {
          type: string;
          description: string;
        };
      };
      required: string[];
    };
    PermissionDeniedError: {
      message: string;
      /**
       * @description * `PermissionDeniedError` - PermissionDeniedError
       * @enum {string}
       */
      code: "PermissionDeniedError";
    };
    /**
     * @description * `PermissionDeniedError` - PermissionDeniedError
     * @enum {string}
     */
    PermissionDeniedErrorCodeEnum: "PermissionDeniedError";
    Project: {
      /** ID */
      project_id: number;
      name: string;
      description?: string | null;
    };
    ProviderAPIConnectionError: {
      message: string;
      /**
       * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
       * @enum {string}
       */
      code: "ProviderAPIConnectionError";
    };
    /**
     * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
     * @enum {string}
     */
    ProviderAPIConnectionErrorCodeEnum: "ProviderAPIConnectionError";
    ProviderAPIStatusError: {
      message: string;
      /**
       * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
       * @enum {string}
       */
      code: "ProviderAPIStatusError";
    };
    /**
     * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
     * @enum {string}
     */
    ProviderAPIStatusErrorCodeEnum: "ProviderAPIStatusError";
    ProviderAPITimeoutError: {
      message: string;
      /**
       * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
       * @enum {string}
       */
      code: "ProviderAPITimeoutError";
    };
    /**
     * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
     * @enum {string}
     */
    ProviderAPITimeoutErrorCodeEnum: "ProviderAPITimeoutError";
    ProviderInternalServerError: {
      message: string;
      /**
       * @description * `ProviderInternalServerError` - ProviderInternalServerError
       * @enum {string}
       */
      code: "ProviderInternalServerError";
    };
    /**
     * @description * `ProviderInternalServerError` - ProviderInternalServerError
     * @enum {string}
     */
    ProviderInternalServerErrorCodeEnum: "ProviderInternalServerError";
    ProviderNotFoundError: {
      message: string;
      /**
       * @description * `ProviderNotFoundError` - ProviderNotFoundError
       * @enum {string}
       */
      code: "ProviderNotFoundError";
    };
    /**
     * @description * `ProviderNotFoundError` - ProviderNotFoundError
     * @enum {string}
     */
    ProviderNotFoundErrorCodeEnum: "ProviderNotFoundError";
    RateLimitError: {
      message: string;
      /**
       * @description * `RateLimitError` - RateLimitError
       * @enum {string}
       */
      code: "RateLimitError";
    };
    /**
     * @description * `RateLimitError` - RateLimitError
     * @enum {string}
     */
    RateLimitErrorCodeEnum: "RateLimitError";
    Repository: {
      id: number;
      name: string;
      description?: string | null;
      organization: string;
    };
    ResponseChoice: {
      /** @description The index of the choice in the list of choices. */
      index: number;
      /** @description The messages in the chat completion. */
      message: {
        /**
         * @description The role of the sender (e.g., 'user' or 'assistant').
         *
         * * `user` - user
         * * `assistant` - assistant
         */
        role: "user" | "assistant";
        /** @description The content of the message. */
        content?: string;
        /**
         * Format: uuid
         * @description The ID of the template to use.
         */
        template_id?: string;
        /** @description The parameters (key: value) to use with the given template. */
        params?: {
          [key: string]: unknown;
        };
      };
      /** @description The reason the chat completion finished, e.g., 'stop' or 'length'. */
      finish_reason: string;
      /** @description The tool calls made. */
      tool_calls?: {
          /**
           * Format: uuid
           * @description The ID of the tool call.
           */
          id: string;
          /** @description The function called. */
          function: {
            /** @description The name of the function to be called. */
            name: string;
            /** @description The arguments passed to the function. */
            arguments?: {
              [key: string]: unknown;
            };
          };
          /** @description The type of tool call. */
          type: string;
        }[] | null;
    };
    /**
     * @description * `PENDING` - Pending
     * * `UPLOADED` - Uploaded
     * * `PARSING` - Parsing
     * * `CHUNKING` - Chunking
     * * `WAITING_FOR_CHUNKS_COMPLETION` - Waiting for chunks completion
     * * `PROCESSING` - Processing
     * * `COMPLETED` - Completed
     * * `FAILED` - Failed
     * @enum {string}
     */
    StatusEnum: "PENDING" | "UPLOADED" | "PARSING" | "CHUNKING" | "WAITING_FOR_CHUNKS_COMPLETION" | "PROCESSING" | "COMPLETED" | "FAILED";
    Tool: {
      /**
       * @description * `function` - function
       * @enum {string}
       */
      type: "function";
      function: {
        name: string;
        description?: string;
        parameters: {
          type: string;
          properties: {
            [key: string]: {
              type: string;
              description: string;
            };
          };
          required: string[];
        };
      };
    };
    ToolCall: {
      /**
       * Format: uuid
       * @description The ID of the tool call.
       */
      id: string;
      /** @description The function called. */
      function: {
        /** @description The name of the function to be called. */
        name: string;
        /** @description The arguments passed to the function. */
        arguments?: {
          [key: string]: unknown;
        };
      };
      /** @description The type of tool call. */
      type: string;
    };
    TraceFeedback: {
      positive: boolean;
      used_datapoint_messages: boolean;
      messages: ({
          /**
           * @description * `user` - user
           * * `assistant` - assistant
           * * `system` - system
           * @enum {string}
           */
          role?: "user" | "assistant" | "system";
          content?: string;
        })[];
    };
    TraceList: {
      /** Format: uuid */
      trace_id: string;
      project_id: number;
      model_id: number;
      feedback: ({
        positive: boolean;
        used_datapoint_messages: boolean;
        messages: ({
            /**
             * @description * `user` - user
             * * `assistant` - assistant
             * * `system` - system
             * @enum {string}
             */
            role?: "user" | "assistant" | "system";
            content?: string;
          })[];
      }) | null;
    };
    TraceRetrieve: {
      /** Format: uuid */
      trace_id: string;
      project: {
        /** ID */
        project_id: number;
        name: string;
        description?: string | null;
      };
      model: {
        id: number;
        name: string;
        /**
         * @description * `text2text` - Text to Text
         * * `text2image` - Text to Image
         * * `text2vector` - Text to Vector
         * * `autopilot` - Autopilot
         * @enum {string}
         */
        model_type?: "text2text" | "text2image" | "text2vector" | "autopilot";
        model_provider?: ("openai" | "azure" | "azure-mistral" | "cohere" | "anthropic" | "cloudflare" | "deepinfra" | "lamini" | "octoai" | "replicate" | "together" | "fireworksai" | "mistralai" | "prem" | "anyscale" | "openrouter" | "perplexity" | "groq") | "" | null;
        deprecated?: boolean;
      };
      session_id?: string | null;
      messages?: ({
          /**
           * @description * `user` - user
           * * `assistant` - assistant
           * * `system` - system
           * @enum {string}
           */
          role?: "user" | "assistant" | "system";
          content?: string;
        })[];
      feedback: ({
        positive: boolean;
        used_datapoint_messages: boolean;
        messages: ({
            /**
             * @description * `user` - user
             * * `assistant` - assistant
             * * `system` - system
             * @enum {string}
             */
            role?: "user" | "assistant" | "system";
            content?: string;
          })[];
      }) | null;
      document_chunks?: ({
          /** ID */
          document_id: number;
          content?: string | null;
        })[];
    };
    TraceRetrieveDocumentChunk: {
      /** ID */
      document_id: number;
      content?: string | null;
    };
    /**
     * @description * `function` - function
     * @enum {string}
     */
    TypeEnum: "function";
    UnprocessableEntityError: {
      message: string;
      /**
       * @description * `UnprocessableEntityError` - UnprocessableEntityError
       * @enum {string}
       */
      code: "UnprocessableEntityError";
    };
    /**
     * @description * `UnprocessableEntityError` - UnprocessableEntityError
     * @enum {string}
     */
    UnprocessableEntityErrorCodeEnum: "UnprocessableEntityError";
    Usage: {
      prompt_tokens: number;
      completion_tokens?: number;
      total_tokens: number;
    };
    ValidationDetail: {
      /** @description Error messages for the field. */
      error_messages: {
          [key: string]: unknown;
        }[];
    };
    ValidationError: {
      /** @description A description of the validation error. */
      message: string;
      /** @description Detailed information about the validation errors. */
      details: {
        [key: string]: {
          /** @description Error messages for the field. */
          error_messages: {
              [key: string]: unknown;
            }[];
        };
      };
      /**
       * @description * `ValidationError` - ValidationError
       * @enum {string}
       */
      code: "ValidationError";
    };
    /**
     * @description * `ValidationError` - ValidationError
     * @enum {string}
     */
    ValidationErrorCodeEnum: "ValidationError";
  };
  responses: never;
  parameters: never;
  requestBodies: never;
  headers: never;
  pathItems: never;
}

export type $defs = Record<string, never>;

export type external = Record<string, never>;

export interface operations {

  /** @description Creates a model response for the given chat conversation. Supports streaming with SSE, [documentation here](https://docs.premai.io/get-started/chat-completion-sse). */
  v1_chat_completions_create: {
    requestBody: {
      content: {
        "application/json": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The ID of the session to use. It helps to track the chat history. */
          session_id?: string;
          /** @description Options for Retrieval Augmented Generation (RAG). Will override launched model settings */
          repositories?: {
            /** @description The IDs of the repositories to use. */
            ids?: number[];
            limit?: number;
            /** Format: double */
            similarity_threshold?: number;
          };
          /** @description A list of messages comprising the conversation so far. */
          messages: ({
              /**
               * @description The role of the sender (e.g., 'user' or 'assistant').
               *
               * * `user` - user
               * * `assistant` - assistant
               */
              role: "user" | "assistant";
              /** @description The content of the message. */
              content?: string;
              /**
               * Format: uuid
               * @description The ID of the template to use.
               */
              template_id?: string;
              /** @description The parameters (key: value) to use with the given template. */
              params?: {
                [key: string]: unknown;
              };
            })[];
          /** @description ID of the model to use. See the model endpoint compatibility table for details. */
          model?: string;
          /** @description The system prompt to use. */
          system_prompt?: string;
          /** @description The maximum number of tokens to generate in the chat completion. */
          max_tokens?: number | null;
          /** @description If set, partial message deltas will be sent, like in ChatGPT. */
          stream?: boolean;
          /**
           * Format: double
           * @description What sampling temperature to use, between 0 and 2.
           * @default 1
           */
          temperature?: number;
          /** @description The tools to use in the completion. */
          tools?: {
              /**
               * @description * `function` - function
               * @enum {string}
               */
              type: "function";
              function: {
                name: string;
                description?: string;
                parameters: {
                  type: string;
                  properties: {
                    [key: string]: {
                      type: string;
                      description: string;
                    };
                  };
                  required: string[];
                };
              };
            }[] | null;
        };
        "application/x-www-form-urlencoded": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The ID of the session to use. It helps to track the chat history. */
          session_id?: string;
          /** @description Options for Retrieval Augmented Generation (RAG). Will override launched model settings */
          repositories?: {
            /** @description The IDs of the repositories to use. */
            ids?: number[];
            limit?: number;
            /** Format: double */
            similarity_threshold?: number;
          };
          /** @description A list of messages comprising the conversation so far. */
          messages: ({
              /**
               * @description The role of the sender (e.g., 'user' or 'assistant').
               *
               * * `user` - user
               * * `assistant` - assistant
               */
              role: "user" | "assistant";
              /** @description The content of the message. */
              content?: string;
              /**
               * Format: uuid
               * @description The ID of the template to use.
               */
              template_id?: string;
              /** @description The parameters (key: value) to use with the given template. */
              params?: {
                [key: string]: unknown;
              };
            })[];
          /** @description ID of the model to use. See the model endpoint compatibility table for details. */
          model?: string;
          /** @description The system prompt to use. */
          system_prompt?: string;
          /** @description The maximum number of tokens to generate in the chat completion. */
          max_tokens?: number | null;
          /** @description If set, partial message deltas will be sent, like in ChatGPT. */
          stream?: boolean;
          /**
           * Format: double
           * @description What sampling temperature to use, between 0 and 2.
           * @default 1
           */
          temperature?: number;
          /** @description The tools to use in the completion. */
          tools?: {
              /**
               * @description * `function` - function
               * @enum {string}
               */
              type: "function";
              function: {
                name: string;
                description?: string;
                parameters: {
                  type: string;
                  properties: {
                    [key: string]: {
                      type: string;
                      description: string;
                    };
                  };
                  required: string[];
                };
              };
            }[] | null;
        };
        "multipart/form-data": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The ID of the session to use. It helps to track the chat history. */
          session_id?: string;
          /** @description Options for Retrieval Augmented Generation (RAG). Will override launched model settings */
          repositories?: {
            /** @description The IDs of the repositories to use. */
            ids?: number[];
            limit?: number;
            /** Format: double */
            similarity_threshold?: number;
          };
          /** @description A list of messages comprising the conversation so far. */
          messages: ({
              /**
               * @description The role of the sender (e.g., 'user' or 'assistant').
               *
               * * `user` - user
               * * `assistant` - assistant
               */
              role: "user" | "assistant";
              /** @description The content of the message. */
              content?: string;
              /**
               * Format: uuid
               * @description The ID of the template to use.
               */
              template_id?: string;
              /** @description The parameters (key: value) to use with the given template. */
              params?: {
                [key: string]: unknown;
              };
            })[];
          /** @description ID of the model to use. See the model endpoint compatibility table for details. */
          model?: string;
          /** @description The system prompt to use. */
          system_prompt?: string;
          /** @description The maximum number of tokens to generate in the chat completion. */
          max_tokens?: number | null;
          /** @description If set, partial message deltas will be sent, like in ChatGPT. */
          stream?: boolean;
          /**
           * Format: double
           * @description What sampling temperature to use, between 0 and 2.
           * @default 1
           */
          temperature?: number;
          /** @description The tools to use in the completion. */
          tools?: {
              /**
               * @description * `function` - function
               * @enum {string}
               */
              type: "function";
              function: {
                name: string;
                description?: string;
                parameters: {
                  type: string;
                  properties: {
                    [key: string]: {
                      type: string;
                      description: string;
                    };
                  };
                  required: string[];
                };
              };
            }[] | null;
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            /** @description A list of chat completion choices. Can be more than one if n is greater than 1. */
            choices: ({
                /** @description The index of the choice in the list of choices. */
                index: number;
                /** @description The messages in the chat completion. */
                message: {
                  /**
                   * @description The role of the sender (e.g., 'user' or 'assistant').
                   *
                   * * `user` - user
                   * * `assistant` - assistant
                   */
                  role: "user" | "assistant";
                  /** @description The content of the message. */
                  content?: string;
                  /**
                   * Format: uuid
                   * @description The ID of the template to use.
                   */
                  template_id?: string;
                  /** @description The parameters (key: value) to use with the given template. */
                  params?: {
                    [key: string]: unknown;
                  };
                };
                /** @description The reason the chat completion finished, e.g., 'stop' or 'length'. */
                finish_reason: string;
                /** @description The tool calls made. */
                tool_calls?: {
                    /**
                     * Format: uuid
                     * @description The ID of the tool call.
                     */
                    id: string;
                    /** @description The function called. */
                    function: {
                      /** @description The name of the function to be called. */
                      name: string;
                      /** @description The arguments passed to the function. */
                      arguments?: {
                        [key: string]: unknown;
                      };
                    };
                    /** @description The type of tool call. */
                    type: string;
                  }[] | null;
              })[];
            /** @description The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp. */
            created: number;
            /** @description The model to generate the completion. */
            model: string;
            /** @description The name of the provider that generated the completion. */
            provider_name: string;
            /** @description The ID of the provider that generated the completion. */
            provider_id: string;
            /** @description Chunks used to improve the completion */
            document_chunks?: {
                repository_id?: number;
                document_id?: number;
                chunk_id?: number;
                document_name?: string;
                /** Format: double */
                similarity_score?: number;
                content?: string;
              }[];
            /** @description The usage statistics for the completion. */
            usage: {
              prompt_tokens: number;
              completion_tokens?: number;
              total_tokens: number;
            };
            /**
             * Format: uuid
             * @description The trace ID of the completion.
             */
            trace_id: string;
          };
        };
      };
      400: {
        content: {
          "application/json": {
            /** @description A description of the validation error. */
            message: string;
            /** @description Detailed information about the validation errors. */
            details: {
              [key: string]: {
                /** @description Error messages for the field. */
                error_messages: {
                    [key: string]: unknown;
                  }[];
              };
            };
            /**
             * @description * `ValidationError` - ValidationError
             * @enum {string}
             */
            code: "ValidationError";
          };
        };
      };
      401: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `AuthenticationError` - AuthenticationError
             * @enum {string}
             */
            code: "AuthenticationError";
          };
        };
      };
      403: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `PermissionDeniedError` - PermissionDeniedError
             * @enum {string}
             */
            code: "PermissionDeniedError";
          };
        };
      };
      404: {
        content: {
          "application/json": OneOf<[{
            message: string;
            /**
             * @description * `ProviderNotFoundError` - ProviderNotFoundError
             * @enum {string}
             */
            code: "ProviderNotFoundError";
          }, {
            message: string;
            /**
             * @description * `ModelNotFoundError` - ModelNotFoundError
             * @enum {string}
             */
            code: "ModelNotFoundError";
          }]>;
        };
      };
      409: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ConflictError` - ConflictError
             * @enum {string}
             */
            code: "ConflictError";
          };
        };
      };
      422: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `UnprocessableEntityError` - UnprocessableEntityError
             * @enum {string}
             */
            code: "UnprocessableEntityError";
          };
        };
      };
      429: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `RateLimitError` - RateLimitError
             * @enum {string}
             */
            code: "RateLimitError";
          };
        };
      };
      500: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ProviderInternalServerError` - ProviderInternalServerError
             * @enum {string}
             */
            code: "ProviderInternalServerError";
          } | {
            message: string;
            /**
             * @description * `APIResponseValidationError` - APIResponseValidationError
             * @enum {string}
             */
            code: "APIResponseValidationError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
             * @enum {string}
             */
            code: "ProviderAPIStatusError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
             * @enum {string}
             */
            code: "ProviderAPITimeoutError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
             * @enum {string}
             */
            code: "ProviderAPIConnectionError";
          } | {
            message: string;
            /**
             * @description * `CatchAllError` - CatchAllError
             * @enum {string}
             */
            code: "CatchAllError";
          };
        };
      };
    };
  };
  /** @description Creates embeddings for the given input. */
  v1_embeddings_create: {
    requestBody: {
      content: {
        "application/json": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The model to generate the embeddings. */
          model: string;
          /** @default float */
          encoding_format?: "float" | "base64";
          /** @description Embedding Input */
          input: string | string[] | number[] | number[][];
        };
        "application/x-www-form-urlencoded": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The model to generate the embeddings. */
          model: string;
          /** @default float */
          encoding_format?: "float" | "base64";
          /** @description Embedding Input */
          input: string | string[] | number[] | number[][];
        };
        "multipart/form-data": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The model to generate the embeddings. */
          model: string;
          /** @default float */
          encoding_format?: "float" | "base64";
          /** @description Embedding Input */
          input: string | string[] | number[] | number[][];
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            /** @description The embeddings for the input. */
            data: {
                /** @description The index of the token in the input. */
                index: number;
                /** @description The embedding for the input. */
                embedding: number[];
              }[];
            /** @description The model to generate the embeddings. */
            model: string;
            /** @description The usage statistics for the completion. */
            usage: {
              prompt_tokens: number;
              completion_tokens?: number;
              total_tokens: number;
            };
            /** @description The name of the provider that generated the completion. */
            provider_name: string;
            /** @description The ID of the provider that generated the completion. */
            provider_id: string;
          };
        };
      };
      400: {
        content: {
          "application/json": {
            /** @description A description of the validation error. */
            message: string;
            /** @description Detailed information about the validation errors. */
            details: {
              [key: string]: {
                /** @description Error messages for the field. */
                error_messages: {
                    [key: string]: unknown;
                  }[];
              };
            };
            /**
             * @description * `ValidationError` - ValidationError
             * @enum {string}
             */
            code: "ValidationError";
          };
        };
      };
      401: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `AuthenticationError` - AuthenticationError
             * @enum {string}
             */
            code: "AuthenticationError";
          };
        };
      };
      403: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `PermissionDeniedError` - PermissionDeniedError
             * @enum {string}
             */
            code: "PermissionDeniedError";
          };
        };
      };
      404: {
        content: {
          "application/json": OneOf<[{
            message: string;
            /**
             * @description * `ProviderNotFoundError` - ProviderNotFoundError
             * @enum {string}
             */
            code: "ProviderNotFoundError";
          }, {
            message: string;
            /**
             * @description * `ModelNotFoundError` - ModelNotFoundError
             * @enum {string}
             */
            code: "ModelNotFoundError";
          }]>;
        };
      };
      409: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ConflictError` - ConflictError
             * @enum {string}
             */
            code: "ConflictError";
          };
        };
      };
      422: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `UnprocessableEntityError` - UnprocessableEntityError
             * @enum {string}
             */
            code: "UnprocessableEntityError";
          };
        };
      };
      429: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `RateLimitError` - RateLimitError
             * @enum {string}
             */
            code: "RateLimitError";
          };
        };
      };
      500: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ProviderInternalServerError` - ProviderInternalServerError
             * @enum {string}
             */
            code: "ProviderInternalServerError";
          } | {
            message: string;
            /**
             * @description * `APIResponseValidationError` - APIResponseValidationError
             * @enum {string}
             */
            code: "APIResponseValidationError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
             * @enum {string}
             */
            code: "ProviderAPIStatusError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
             * @enum {string}
             */
            code: "ProviderAPITimeoutError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
             * @enum {string}
             */
            code: "ProviderAPIConnectionError";
          } | {
            message: string;
            /**
             * @description * `CatchAllError` - CatchAllError
             * @enum {string}
             */
            code: "CatchAllError";
          };
        };
      };
    };
  };
  v1_models_list: {
    responses: {
      200: {
        content: {
          "application/json": ({
              id: number;
              name: string;
              /**
               * @description * `text2text` - Text to Text
               * * `text2image` - Text to Image
               * * `text2vector` - Text to Vector
               * * `autopilot` - Autopilot
               * @enum {string}
               */
              model_type?: "text2text" | "text2image" | "text2vector" | "autopilot";
              model_provider?: ("openai" | "azure" | "azure-mistral" | "cohere" | "anthropic" | "cloudflare" | "deepinfra" | "lamini" | "octoai" | "replicate" | "together" | "fireworksai" | "mistralai" | "prem" | "anyscale" | "openrouter" | "perplexity" | "groq") | "" | null;
              deprecated?: boolean;
            })[];
        };
      };
    };
  };
  v1_models_retrieve: {
    parameters: {
      path: {
        /** @description A unique integer value identifying this Model. */
        id: number;
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            id: number;
            name: string;
            /**
             * @description * `text2text` - Text to Text
             * * `text2image` - Text to Image
             * * `text2vector` - Text to Vector
             * * `autopilot` - Autopilot
             * @enum {string}
             */
            model_type?: "text2text" | "text2image" | "text2vector" | "autopilot";
            model_provider?: ("openai" | "azure" | "azure-mistral" | "cohere" | "anthropic" | "cloudflare" | "deepinfra" | "lamini" | "octoai" | "replicate" | "together" | "fireworksai" | "mistralai" | "prem" | "anyscale" | "openrouter" | "perplexity" | "groq") | "" | null;
            deprecated?: boolean;
          };
        };
      };
    };
  };
  v1_repositories_create: {
    requestBody: {
      content: {
        "application/json": {
          id: number;
          name: string;
          description?: string | null;
          organization: string;
        };
        "application/x-www-form-urlencoded": {
          id: number;
          name: string;
          description?: string | null;
          organization: string;
        };
        "multipart/form-data": {
          id: number;
          name: string;
          description?: string | null;
          organization: string;
        };
      };
    };
    responses: {
      201: {
        content: {
          "application/json": {
            id: number;
            name: string;
            description?: string | null;
            organization: string;
          };
        };
      };
    };
  };
  v1_repository_document_create: {
    parameters: {
      path: {
        repository_id: number;
      };
    };
    requestBody: {
      content: {
        "multipart/form-data": {
          /** Format: uri */
          file: string;
        };
      };
    };
    responses: {
      201: {
        content: {
          "application/json": {
            repository_id: number;
            document_id: number;
            name: string;
            /**
             * @description * `pdf` - PDF
             * * `docx` - Word
             * * `txt` - Text
             * @enum {string}
             */
            document_type: "pdf" | "docx" | "txt";
            /**
             * @description * `PENDING` - Pending
             * * `UPLOADED` - Uploaded
             * * `PARSING` - Parsing
             * * `CHUNKING` - Chunking
             * * `WAITING_FOR_CHUNKS_COMPLETION` - Waiting for chunks completion
             * * `PROCESSING` - Processing
             * * `COMPLETED` - Completed
             * * `FAILED` - Failed
             * @enum {string}
             */
            status: "PENDING" | "UPLOADED" | "PARSING" | "CHUNKING" | "WAITING_FOR_CHUNKS_COMPLETION" | "PROCESSING" | "COMPLETED" | "FAILED";
            error: string | null;
            /** @default 0 */
            chunk_count: number;
          };
        };
      };
    };
  };
  /** @description Set trace feedback */
  v1_set_trace_feedback_create: {
    requestBody: {
      content: {
        "application/json": {
          /** Format: uuid */
          trace_id: string;
          feedback?: ({
            /** @default false */
            positive?: boolean;
            messages?: ({
                /**
                 * @description * `user` - user
                 * * `assistant` - assistant
                 * * `system` - system
                 * @enum {string}
                 */
                role?: "user" | "assistant" | "system";
                content?: string;
              })[];
          }) | null;
        };
        "application/x-www-form-urlencoded": {
          /** Format: uuid */
          trace_id: string;
          feedback?: ({
            /** @default false */
            positive?: boolean;
            messages?: ({
                /**
                 * @description * `user` - user
                 * * `assistant` - assistant
                 * * `system` - system
                 * @enum {string}
                 */
                role?: "user" | "assistant" | "system";
                content?: string;
              })[];
          }) | null;
        };
        "multipart/form-data": {
          /** Format: uuid */
          trace_id: string;
          feedback?: ({
            /** @default false */
            positive?: boolean;
            messages?: ({
                /**
                 * @description * `user` - user
                 * * `assistant` - assistant
                 * * `system` - system
                 * @enum {string}
                 */
                role?: "user" | "assistant" | "system";
                content?: string;
              })[];
          }) | null;
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            /** Format: uuid */
            trace_id: string;
            feedback?: ({
              /** @default false */
              positive?: boolean;
              messages?: ({
                  /**
                   * @description * `user` - user
                   * * `assistant` - assistant
                   * * `system` - system
                   * @enum {string}
                   */
                  role?: "user" | "assistant" | "system";
                  content?: string;
                })[];
            }) | null;
          };
        };
      };
    };
  };
  v1_traces_list: {
    parameters: {
      query: {
        project_id: number;
      };
    };
    responses: {
      200: {
        content: {
          "application/json": ({
              /** Format: uuid */
              trace_id: string;
              project_id: number;
              model_id: number;
              feedback: ({
                positive: boolean;
                used_datapoint_messages: boolean;
                messages: ({
                    /**
                     * @description * `user` - user
                     * * `assistant` - assistant
                     * * `system` - system
                     * @enum {string}
                     */
                    role?: "user" | "assistant" | "system";
                    content?: string;
                  })[];
              }) | null;
            })[];
        };
      };
    };
  };
  v1_traces_retrieve: {
    parameters: {
      path: {
        /** @description A UUID string identifying this Trace. */
        id: string;
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            /** Format: uuid */
            trace_id: string;
            project: {
              /** ID */
              project_id: number;
              name: string;
              description?: string | null;
            };
            model: {
              id: number;
              name: string;
              /**
               * @description * `text2text` - Text to Text
               * * `text2image` - Text to Image
               * * `text2vector` - Text to Vector
               * * `autopilot` - Autopilot
               * @enum {string}
               */
              model_type?: "text2text" | "text2image" | "text2vector" | "autopilot";
              model_provider?: ("openai" | "azure" | "azure-mistral" | "cohere" | "anthropic" | "cloudflare" | "deepinfra" | "lamini" | "octoai" | "replicate" | "together" | "fireworksai" | "mistralai" | "prem" | "anyscale" | "openrouter" | "perplexity" | "groq") | "" | null;
              deprecated?: boolean;
            };
            session_id?: string | null;
            messages?: ({
                /**
                 * @description * `user` - user
                 * * `assistant` - assistant
                 * * `system` - system
                 * @enum {string}
                 */
                role?: "user" | "assistant" | "system";
                content?: string;
              })[];
            feedback: ({
              positive: boolean;
              used_datapoint_messages: boolean;
              messages: ({
                  /**
                   * @description * `user` - user
                   * * `assistant` - assistant
                   * * `system` - system
                   * @enum {string}
                   */
                  role?: "user" | "assistant" | "system";
                  content?: string;
                })[];
            }) | null;
            document_chunks?: ({
                /** ID */
                document_id: number;
                content?: string | null;
              })[];
          };
        };
      };
    };
  };
}
