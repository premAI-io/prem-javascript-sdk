/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */


/** OneOf type helpers */
type Without<T, U> = { [P in Exclude<keyof T, keyof U>]?: never };
type XOR<T, U> = (T | U) extends object ? (Without<T, U> & U) | (Without<U, T> & T) : T | U;
type OneOf<T extends any[]> = T extends [infer Only] ? Only : T extends [infer A, infer B, ...infer Rest] ? OneOf<[XOR<A, B>, ...Rest]> : never;

export interface paths {
  "/api/repositories/repositories/": {
    post: operations["api_repositories_repositories_create"];
  };
  "/api/repositories/repository/{repository_id}/document": {
    post: operations["api_repositories_repository_document_create"];
  };
  "/v1/chat/completions": {
    /** @description Creates a model response for the given chat conversation. Supports streaming with SSE, [documentation here](https://docs.premai.io/get-started/chat-completion-sse). */
    post: operations["v1_chat_completions_create"];
  };
  "/v1/create_finetuning_job": {
    /** @description Creates a finetuning job for the given project and model. */
    post: operations["v1_create_finetuning_job_create"];
  };
  "/v1/delete_finetuning_job": {
    /** @description Delete a finetuning job */
    post: operations["v1_delete_finetuning_job_create"];
  };
  "/v1/download_finetuned_model": {
    /** @description Download a finetuned model */
    post: operations["v1_download_finetuned_model_create"];
  };
  "/v1/embeddings": {
    /** @description Creates embeddings for the given input. */
    post: operations["v1_embeddings_create"];
  };
  "/v1/finetuned_model_try": {
    /** @description Try out a finetuned model by creating a new playground */
    post: operations["v1_finetuned_model_try_create"];
  };
  "/v1/finetuning_job_details": {
    /** @description Get details for a fine-tuning job */
    post: operations["v1_finetuning_job_details_create"];
  };
  "/v1/get_dataset": {
    get: operations["v1_get_dataset_retrieve"];
  };
  "/v1/init_page_data": {
    /** @description Get initialization data for a project page */
    post: operations["v1_init_page_data_create"];
  };
  "/v1/models/": {
    get: operations["v1_models_list"];
  };
  "/v1/models/{id}/": {
    get: operations["v1_models_retrieve"];
  };
  "/v1/set_trace_feedback": {
    /** @description Set trace feedback */
    post: operations["v1_set_trace_feedback_create"];
  };
  "/v1/traces/": {
    get: operations["v1_traces_list"];
  };
  "/v1/traces/{id}/": {
    get: operations["v1_traces_retrieve"];
  };
}

export type webhooks = Record<string, never>;

export interface components {
  schemas: {
    APIResponseValidationError: {
      message: string;
      /**
       * @description * `APIResponseValidationError` - APIResponseValidationError
       * @enum {string}
       */
      code: "APIResponseValidationError";
    };
    /**
     * @description * `APIResponseValidationError` - APIResponseValidationError
     * @enum {string}
     */
    APIResponseValidationErrorCodeEnum: "APIResponseValidationError";
    AuthenticationError: {
      message: string;
      /**
       * @description * `AuthenticationError` - AuthenticationError
       * @enum {string}
       */
      code: "AuthenticationError";
    };
    /**
     * @description * `AuthenticationError` - AuthenticationError
     * @enum {string}
     */
    AuthenticationErrorCodeEnum: "AuthenticationError";
    /** @enum {unknown} */
    BlankEnum: "";
    CatchAllError: {
      message: string;
      /**
       * @description * `CatchAllError` - CatchAllError
       * @enum {string}
       */
      code: "CatchAllError";
    };
    /**
     * @description * `CatchAllError` - CatchAllError
     * @enum {string}
     */
    CatchAllErrorCodeEnum: "CatchAllError";
    ChatCompletionInput: {
      /** @description The ID of the project to use. */
      project_id: number;
      /** @description The ID of the session to use. It helps to track the chat history. */
      session_id?: string;
      /** @description Options for Retrieval Augmented Generation (RAG). Will override launched model settings */
      repositories?: {
        /** @description The IDs of the repositories to use. */
        ids?: number[];
        limit?: number;
        /** Format: double */
        similarity_threshold?: number;
      };
      /** @description A list of messages comprising the conversation so far. */
      messages: ({
          /**
           * @description The role of the sender (e.g., 'user' or 'assistant').
           *
           * * `user` - user
           * * `assistant` - assistant
           */
          role: "user" | "assistant";
          /** @description The content of the message. */
          content?: OneOf<[string, ({
              /** @enum {string} */
              type: "text" | "image_url";
              text?: string;
              image_url?: {
                url: string;
              };
            })[]]>;
          /**
           * Format: uuid
           * @description The ID of the template to use.
           */
          template_id?: string;
          /** @description The parameters (key: value) to use with the given template. */
          params?: {
            [key: string]: unknown;
          };
        })[];
      /** @description ID of the model to use. See the model endpoint compatibility table for details. */
      model?: string;
      /** @description The system prompt to use. */
      system_prompt?: string;
      /** @description The maximum number of tokens to generate in the chat completion. */
      max_tokens?: number | null;
      /** @description If set, partial message deltas will be sent, like in ChatGPT. */
      stream?: boolean;
      /**
       * Format: double
       * @description What sampling temperature to use, between 0 and 2.
       * @default 1
       */
      temperature?: number;
      /** @description The tools to use in the completion. */
      tools?: {
          /**
           * @description * `function` - function
           * @enum {string}
           */
          type: "function";
          function: {
            name: string;
            description?: string;
            parameters: {
              type: string;
              properties: {
                [key: string]: {
                  type: string;
                  description: string;
                };
              };
              required: string[];
            };
          };
        }[] | null;
      /** @description The format of the response. Can be a JSON schema or a simple `json_object` type */
      response_format?: {
        [key: string]: unknown;
      } | null;
    };
    ChatCompletionResponse: {
      /** @description A list of chat completion choices. Can be more than one if n is greater than 1. */
      choices: ({
          /** @description The index of the choice in the list of choices. */
          index: number;
          /** @description The messages in the chat completion. */
          message: {
            /**
             * @description The role of the sender (e.g., 'user' or 'assistant').
             *
             * * `user` - user
             * * `assistant` - assistant
             */
            role: "user" | "assistant";
            /** @description The content of the message. */
            content?: OneOf<[string, ({
                /** @enum {string} */
                type: "text" | "image_url";
                text?: string;
                image_url?: {
                  url: string;
                };
              })[]]>;
            /**
             * Format: uuid
             * @description The ID of the template to use.
             */
            template_id?: string;
            /** @description The parameters (key: value) to use with the given template. */
            params?: {
              [key: string]: unknown;
            };
          };
          /** @description The reason the chat completion finished, e.g., 'stop' or 'length'. */
          finish_reason: string;
          /** @description The tool calls made. */
          tool_calls?: {
              /**
               * Format: uuid
               * @description The ID of the tool call.
               */
              id: string;
              /** @description The function called. */
              function: {
                /** @description The name of the function to be called. */
                name: string;
                /** @description The arguments passed to the function. */
                arguments?: {
                  [key: string]: unknown;
                };
              };
              /** @description The type of tool call. */
              type: string;
            }[] | null;
        })[];
      /** @description The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp. */
      created: number;
      /** @description The model to generate the completion. */
      model: string;
      /** @description The name of the provider that generated the completion. */
      provider_name: string;
      /** @description The ID of the provider that generated the completion. */
      provider_id: string;
      /** @description Chunks used to improve the completion */
      document_chunks?: {
          repository_id?: number;
          document_id?: number;
          chunk_id?: number;
          document_name?: string;
          /** Format: double */
          similarity_score?: number;
          content?: string;
        }[];
      /** @description The usage statistics for the completion. */
      usage: {
        prompt_tokens: number;
        completion_tokens?: number;
        total_tokens: number;
      };
      /**
       * Format: uuid
       * @description The trace ID of the completion.
       */
      trace_id: string;
    };
    ConflictError: {
      message: string;
      /**
       * @description * `ConflictError` - ConflictError
       * @enum {string}
       */
      code: "ConflictError";
    };
    /**
     * @description * `ConflictError` - ConflictError
     * @enum {string}
     */
    ConflictErrorCodeEnum: "ConflictError";
    Datapoint: {
      messages: ({
          /**
           * @description * `user` - user
           * * `assistant` - assistant
           * * `system` - system
           * @enum {string}
           */
          role?: "user" | "assistant" | "system";
          content?: string;
        })[];
    };
    DeleteFinetuningJobRequest: {
      /** @description The ID of the project */
      project_id: number;
      /** @description The ID of the finetuning job to delete */
      fine_tuning_job_id: number;
    };
    DocumentChunks: {
      repository_id?: number;
      document_id?: number;
      chunk_id?: number;
      document_name?: string;
      /** Format: double */
      similarity_score?: number;
      content?: string;
    };
    DocumentInput: {
      /** Format: uri */
      file: string;
    };
    DocumentOutput: {
      repository_id: number;
      document_id: number;
      name: string;
      /**
       * @description * `pdf` - PDF
       * * `docx` - Word
       * * `txt` - Text
       * @enum {string}
       */
      document_type: "pdf" | "docx" | "txt";
      /**
       * @description * `PENDING` - Pending
       * * `UPLOADED` - Uploaded
       * * `INDEXING` - Indexing
       * * `COMPLETED` - Completed
       * * `FAILED` - Failed
       * @enum {string}
       */
      status: "PENDING" | "UPLOADED" | "INDEXING" | "COMPLETED" | "FAILED";
      error: string | null;
      /** @default 0 */
      chunk_count: number;
    };
    /**
     * @description * `pdf` - PDF
     * * `docx` - Word
     * * `txt` - Text
     * @enum {string}
     */
    DocumentTypeEnum: "pdf" | "docx" | "txt";
    DownloadFinetunedModelRequest: {
      /** @description The ID of the project */
      project_id: number;
      /** @description The ID of the finetuned job to download */
      fine_tuning_job_id: number;
    };
    Embedding: {
      /** @description The index of the token in the input. */
      index: number;
      /** @description The embedding for the input. */
      embedding: number[];
    };
    EmbeddingsInput: {
      /** @description The ID of the project to use. */
      project_id: number;
      /** @description The model to generate the embeddings. */
      model: string;
      /** @default float */
      encoding_format?: "float" | "base64";
      /** @description Embedding Input */
      input: string | string[] | number[] | number[][];
    };
    EmbeddingsResponse: {
      /** @description The embeddings for the input. */
      data: {
          /** @description The index of the token in the input. */
          index: number;
          /** @description The embedding for the input. */
          embedding: number[];
        }[];
      /** @description The model to generate the embeddings. */
      model: string;
      /** @description The usage statistics for the completion. */
      usage: {
        prompt_tokens: number;
        completion_tokens?: number;
        total_tokens: number;
      };
      /** @description The name of the provider that generated the completion. */
      provider_name: string;
      /** @description The ID of the provider that generated the completion. */
      provider_id: string;
    };
    /**
     * @description * `float` - float
     * * `base64` - base64
     * @enum {string}
     */
    EncodingFormatEnum: "float" | "base64";
    Enhancement: {
      /** @description The IDs of the repositories to use. */
      ids?: number[];
      limit?: number;
      /** Format: double */
      similarity_threshold?: number;
    };
    FeedbackCreate: {
      feedback?: ({
        /** @default false */
        positive?: boolean;
        messages?: ({
            /**
             * @description * `user` - user
             * * `assistant` - assistant
             * * `system` - system
             * @enum {string}
             */
            role?: "user" | "assistant" | "system";
            content?: string;
          })[];
      }) | null;
    };
    FeedbackCreateFeedback: {
      /** @default false */
      positive?: boolean;
      messages?: ({
          /**
           * @description * `user` - user
           * * `assistant` - assistant
           * * `system` - system
           * @enum {string}
           */
          role?: "user" | "assistant" | "system";
          content?: string;
        })[];
    };
    FineTunedModelTryRequest: {
      /** @description The ID of the finetuned model to try */
      model_id: number;
      /**
       * @description System prompt to use for the model
       * @default You are a helpful assistant.
       */
      system_prompt?: string;
      /** @description The ID of the project */
      project_id: number;
    };
    FineTunedModelTryResponse: {
      success: string;
      playground_url: string;
    };
    FineTuningJobCreate: {
      /** @description The id of the project to use for finetuning */
      project_id: number;
      /**
       * @description Name of the fine-tuning job
       * @default
       */
      name?: string;
      /** @description The slug of the base model to use for finetuning */
      base_model: string;
      /** @description The datapoints to use for finetuning */
      datapoints: ({
          messages: ({
              /**
               * @description * `user` - user
               * * `assistant` - assistant
               * * `system` - system
               * @enum {string}
               */
              role?: "user" | "assistant" | "system";
              content?: string;
            })[];
        })[];
      /** @description Hyperparameters for fine-tuning job */
      hyperparameters: {
        /** @description Batch size for fine-tuning */
        batch_size: number;
        /**
         * Format: double
         * @description Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.
         */
        learning_rate_multiplier: number;
        /** @description Number of epochs for fine-tuning */
        num_epochs: number;
      };
      /** @description Synthetic datageneration parameters for fine-tuning job */
      synthetic_datageneration_parameters: {
        /** @description Whether to run synthetic datageneration */
        run_synthetic_datageneration: boolean;
        /** @description Minimum number of datapoints required for fine-tuning */
        min_num_datapoints_for_ft: number;
        /**
         * Format: double
         * @description Temperature for synthetic datageneration
         */
        temperature: number;
        /** @description Positive instructions for synthetic datageneration, what the datapoints should be about */
        positive_instructions: string;
        /** @description Negative instructions for synthetic datageneration, what the datapoints should not be about */
        negative_instructions: string;
      };
    };
    FineTuningJobCreateResponse: {
      successful: string;
      job_id: number;
      job_status: string;
    };
    FineTuningJobDetailsRequest: {
      project_id: number;
      fine_tuning_job_id: number;
    };
    FineTuningJobHyperparameters: {
      /** @description Batch size for fine-tuning */
      batch_size: number;
      /**
       * Format: double
       * @description Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.
       */
      learning_rate_multiplier: number;
      /** @description Number of epochs for fine-tuning */
      num_epochs: number;
    };
    FineTuningJobResponse: {
      name: string;
      baseModel: string;
      status: string;
      originalDataset: ({
          messages: ({
              /**
               * @description * `user` - user
               * * `assistant` - assistant
               * * `system` - system
               * @enum {string}
               */
              role?: "user" | "assistant" | "system";
              content?: string;
            })[];
        })[];
      augmentedDataset: ({
          messages: ({
              /**
               * @description * `user` - user
               * * `assistant` - assistant
               * * `system` - system
               * @enum {string}
               */
              role?: "user" | "assistant" | "system";
              content?: string;
            })[];
        })[];
      numTopics: number;
      numAugmentedDatapoints: number;
      /** Format: date-time */
      createdAt: string;
      evaluationScores?: {
        [key: string]: unknown;
      };
      finetunedModelId: number;
      id: number;
      providerJobId: string;
      hyperparameters: {
        /** @description Batch size for fine-tuning */
        batch_size: number;
        /**
         * Format: double
         * @description Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.
         */
        learning_rate_multiplier: number;
        /** @description Number of epochs for fine-tuning */
        num_epochs: number;
      };
      syntheticDatagenerationParameters: {
        /** @description Whether to run synthetic datageneration */
        run_synthetic_datageneration: boolean;
        /** @description Minimum number of datapoints required for fine-tuning */
        min_num_datapoints_for_ft: number;
        /**
         * Format: double
         * @description Temperature for synthetic datageneration
         */
        temperature: number;
        /** @description Positive instructions for synthetic datageneration, what the datapoints should be about */
        positive_instructions: string;
        /** @description Negative instructions for synthetic datageneration, what the datapoints should not be about */
        negative_instructions: string;
      };
      error?: {
        [key: string]: unknown;
      };
    };
    FineTuningJobSyntheticDatagenerationParameters: {
      /** @description Whether to run synthetic datageneration */
      run_synthetic_datageneration: boolean;
      /** @description Minimum number of datapoints required for fine-tuning */
      min_num_datapoints_for_ft: number;
      /**
       * Format: double
       * @description Temperature for synthetic datageneration
       */
      temperature: number;
      /** @description Positive instructions for synthetic datageneration, what the datapoints should be about */
      positive_instructions: string;
      /** @description Negative instructions for synthetic datageneration, what the datapoints should not be about */
      negative_instructions: string;
    };
    Function: {
      name: string;
      description?: string;
      parameters: {
        type: string;
        properties: {
          [key: string]: {
            type: string;
            description: string;
          };
        };
        required: string[];
      };
    };
    InitPageDataRequest: {
      project_id: number;
    };
    InitPageDataResponse: {
      ftJobs: ({
          name: string;
          baseModel: string;
          status: string;
          originalDataset: ({
              messages: ({
                  /**
                   * @description * `user` - user
                   * * `assistant` - assistant
                   * * `system` - system
                   * @enum {string}
                   */
                  role?: "user" | "assistant" | "system";
                  content?: string;
                })[];
            })[];
          augmentedDataset: ({
              messages: ({
                  /**
                   * @description * `user` - user
                   * * `assistant` - assistant
                   * * `system` - system
                   * @enum {string}
                   */
                  role?: "user" | "assistant" | "system";
                  content?: string;
                })[];
            })[];
          numTopics: number;
          numAugmentedDatapoints: number;
          /** Format: date-time */
          createdAt: string;
          evaluationScores?: {
            [key: string]: unknown;
          };
          finetunedModelId: number;
          id: number;
          providerJobId: string;
          hyperparameters: {
            /** @description Batch size for fine-tuning */
            batch_size: number;
            /**
             * Format: double
             * @description Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.
             */
            learning_rate_multiplier: number;
            /** @description Number of epochs for fine-tuning */
            num_epochs: number;
          };
          syntheticDatagenerationParameters: {
            /** @description Whether to run synthetic datageneration */
            run_synthetic_datageneration: boolean;
            /** @description Minimum number of datapoints required for fine-tuning */
            min_num_datapoints_for_ft: number;
            /**
             * Format: double
             * @description Temperature for synthetic datageneration
             */
            temperature: number;
            /** @description Positive instructions for synthetic datageneration, what the datapoints should be about */
            positive_instructions: string;
            /** @description Negative instructions for synthetic datageneration, what the datapoints should not be about */
            negative_instructions: string;
          };
          error?: {
            [key: string]: unknown;
          };
        })[];
    };
    InternalServerError: {
      message: string;
      /**
       * @description * `ProviderInternalServerError` - ProviderInternalServerError
       * @enum {string}
       */
      code: "ProviderInternalServerError";
    } | {
      message: string;
      /**
       * @description * `APIResponseValidationError` - APIResponseValidationError
       * @enum {string}
       */
      code: "APIResponseValidationError";
    } | {
      message: string;
      /**
       * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
       * @enum {string}
       */
      code: "ProviderAPIStatusError";
    } | {
      message: string;
      /**
       * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
       * @enum {string}
       */
      code: "ProviderAPITimeoutError";
    } | {
      message: string;
      /**
       * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
       * @enum {string}
       */
      code: "ProviderAPIConnectionError";
    } | {
      message: string;
      /**
       * @description * `CatchAllError` - CatchAllError
       * @enum {string}
       */
      code: "CatchAllError";
    };
    Message: {
      /**
       * @description The role of the sender (e.g., 'user' or 'assistant').
       *
       * * `user` - user
       * * `assistant` - assistant
       */
      role: "user" | "assistant";
      /** @description The content of the message. */
      content?: OneOf<[string, ({
          /** @enum {string} */
          type: "text" | "image_url";
          text?: string;
          image_url?: {
            url: string;
          };
        })[]]>;
      /**
       * Format: uuid
       * @description The ID of the template to use.
       */
      template_id?: string;
      /** @description The parameters (key: value) to use with the given template. */
      params?: {
        [key: string]: unknown;
      };
    };
    /**
     * @description * `user` - user
     * * `assistant` - assistant
     * @enum {string}
     */
    MessageRoleEnum: "user" | "assistant";
    Messages: {
      /**
       * @description * `user` - user
       * * `assistant` - assistant
       * * `system` - system
       * @enum {string}
       */
      role?: "user" | "assistant" | "system";
      content?: string;
    };
    /**
     * @description * `user` - user
     * * `assistant` - assistant
     * * `system` - system
     * @enum {string}
     */
    MessagesRoleEnum: "user" | "assistant" | "system";
    Model: {
      id: number;
      name: string;
      /**
       * @description * `text2text` - Text to Text
       * * `text2image` - Text to Image
       * * `text2vector` - Text to Vector
       * @enum {string}
       */
      model_type?: "text2text" | "text2image" | "text2vector";
      model_provider?: ("openai" | "azure" | "anthropic" | "prem" | "groq" | "proxy-prem-ai") | "" | null;
      deprecated?: boolean;
    };
    ModelNotFoundError: {
      message: string;
      /**
       * @description * `ModelNotFoundError` - ModelNotFoundError
       * @enum {string}
       */
      code: "ModelNotFoundError";
    };
    /**
     * @description * `ModelNotFoundError` - ModelNotFoundError
     * @enum {string}
     */
    ModelNotFoundErrorCodeEnum: "ModelNotFoundError";
    /**
     * @description * `openai` - OpenAI
     * * `azure` - Azure OpenAI
     * * `anthropic` - Anthropic
     * * `prem` - Prem AI
     * * `groq` - Groq
     * * `proxy-prem-ai` - Proxy Prem AI
     * @enum {string}
     */
    ModelProviderEnum: "openai" | "azure" | "anthropic" | "prem" | "groq" | "proxy-prem-ai";
    /**
     * @description * `text2text` - Text to Text
     * * `text2image` - Text to Image
     * * `text2vector` - Text to Vector
     * @enum {string}
     */
    ModelTypeEnum: "text2text" | "text2image" | "text2vector";
    NotFoundError: OneOf<[{
      message: string;
      /**
       * @description * `ProviderNotFoundError` - ProviderNotFoundError
       * @enum {string}
       */
      code: "ProviderNotFoundError";
    }, {
      message: string;
      /**
       * @description * `ModelNotFoundError` - ModelNotFoundError
       * @enum {string}
       */
      code: "ModelNotFoundError";
    }]>;
    /** @enum {unknown} */
    NullEnum: "";
    OutputFunction: {
      /** @description The name of the function to be called. */
      name: string;
      /** @description The arguments passed to the function. */
      arguments?: {
        [key: string]: unknown;
      };
    };
    ParameterProperties: {
      type: string;
      description: string;
    };
    Parameters: {
      type: string;
      properties: {
        [key: string]: {
          type: string;
          description: string;
        };
      };
      required: string[];
    };
    PermissionDeniedError: {
      message: string;
      /**
       * @description * `PermissionDeniedError` - PermissionDeniedError
       * @enum {string}
       */
      code: "PermissionDeniedError";
    };
    /**
     * @description * `PermissionDeniedError` - PermissionDeniedError
     * @enum {string}
     */
    PermissionDeniedErrorCodeEnum: "PermissionDeniedError";
    Project: {
      /** ID */
      project_id: number;
      name: string;
      description?: string | null;
    };
    ProviderAPIConnectionError: {
      message: string;
      /**
       * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
       * @enum {string}
       */
      code: "ProviderAPIConnectionError";
    };
    /**
     * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
     * @enum {string}
     */
    ProviderAPIConnectionErrorCodeEnum: "ProviderAPIConnectionError";
    ProviderAPIStatusError: {
      message: string;
      /**
       * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
       * @enum {string}
       */
      code: "ProviderAPIStatusError";
    };
    /**
     * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
     * @enum {string}
     */
    ProviderAPIStatusErrorCodeEnum: "ProviderAPIStatusError";
    ProviderAPITimeoutError: {
      message: string;
      /**
       * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
       * @enum {string}
       */
      code: "ProviderAPITimeoutError";
    };
    /**
     * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
     * @enum {string}
     */
    ProviderAPITimeoutErrorCodeEnum: "ProviderAPITimeoutError";
    ProviderInternalServerError: {
      message: string;
      /**
       * @description * `ProviderInternalServerError` - ProviderInternalServerError
       * @enum {string}
       */
      code: "ProviderInternalServerError";
    };
    /**
     * @description * `ProviderInternalServerError` - ProviderInternalServerError
     * @enum {string}
     */
    ProviderInternalServerErrorCodeEnum: "ProviderInternalServerError";
    ProviderNotFoundError: {
      message: string;
      /**
       * @description * `ProviderNotFoundError` - ProviderNotFoundError
       * @enum {string}
       */
      code: "ProviderNotFoundError";
    };
    /**
     * @description * `ProviderNotFoundError` - ProviderNotFoundError
     * @enum {string}
     */
    ProviderNotFoundErrorCodeEnum: "ProviderNotFoundError";
    RateLimitError: {
      message: string;
      /**
       * @description * `RateLimitError` - RateLimitError
       * @enum {string}
       */
      code: "RateLimitError";
    };
    /**
     * @description * `RateLimitError` - RateLimitError
     * @enum {string}
     */
    RateLimitErrorCodeEnum: "RateLimitError";
    Repository: {
      id: number;
      name: string;
      description?: string | null;
      organization: string;
    };
    ResponseChoice: {
      /** @description The index of the choice in the list of choices. */
      index: number;
      /** @description The messages in the chat completion. */
      message: {
        /**
         * @description The role of the sender (e.g., 'user' or 'assistant').
         *
         * * `user` - user
         * * `assistant` - assistant
         */
        role: "user" | "assistant";
        /** @description The content of the message. */
        content?: OneOf<[string, ({
            /** @enum {string} */
            type: "text" | "image_url";
            text?: string;
            image_url?: {
              url: string;
            };
          })[]]>;
        /**
         * Format: uuid
         * @description The ID of the template to use.
         */
        template_id?: string;
        /** @description The parameters (key: value) to use with the given template. */
        params?: {
          [key: string]: unknown;
        };
      };
      /** @description The reason the chat completion finished, e.g., 'stop' or 'length'. */
      finish_reason: string;
      /** @description The tool calls made. */
      tool_calls?: {
          /**
           * Format: uuid
           * @description The ID of the tool call.
           */
          id: string;
          /** @description The function called. */
          function: {
            /** @description The name of the function to be called. */
            name: string;
            /** @description The arguments passed to the function. */
            arguments?: {
              [key: string]: unknown;
            };
          };
          /** @description The type of tool call. */
          type: string;
        }[] | null;
    };
    /**
     * @description * `PENDING` - Pending
     * * `UPLOADED` - Uploaded
     * * `INDEXING` - Indexing
     * * `COMPLETED` - Completed
     * * `FAILED` - Failed
     * @enum {string}
     */
    StatusEnum: "PENDING" | "UPLOADED" | "INDEXING" | "COMPLETED" | "FAILED";
    Tool: {
      /**
       * @description * `function` - function
       * @enum {string}
       */
      type: "function";
      function: {
        name: string;
        description?: string;
        parameters: {
          type: string;
          properties: {
            [key: string]: {
              type: string;
              description: string;
            };
          };
          required: string[];
        };
      };
    };
    ToolCall: {
      /**
       * Format: uuid
       * @description The ID of the tool call.
       */
      id: string;
      /** @description The function called. */
      function: {
        /** @description The name of the function to be called. */
        name: string;
        /** @description The arguments passed to the function. */
        arguments?: {
          [key: string]: unknown;
        };
      };
      /** @description The type of tool call. */
      type: string;
    };
    TraceFeedback: {
      positive: boolean;
      used_datapoint_messages: boolean;
      messages: ({
          /**
           * @description * `user` - user
           * * `assistant` - assistant
           * * `system` - system
           * @enum {string}
           */
          role?: "user" | "assistant" | "system";
          content?: string;
        })[];
    };
    TraceList: {
      /** Format: uuid */
      trace_id: string;
      project_id: number;
      model_id: number;
      messages?: ({
          /**
           * @description * `user` - user
           * * `assistant` - assistant
           * * `system` - system
           * @enum {string}
           */
          role?: "user" | "assistant" | "system";
          content?: string;
        })[];
      feedback: ({
        positive: boolean;
        used_datapoint_messages: boolean;
        messages: ({
            /**
             * @description * `user` - user
             * * `assistant` - assistant
             * * `system` - system
             * @enum {string}
             */
            role?: "user" | "assistant" | "system";
            content?: string;
          })[];
      }) | null;
    };
    TraceRetrieve: {
      /** Format: uuid */
      trace_id: string;
      project: {
        /** ID */
        project_id: number;
        name: string;
        description?: string | null;
      };
      model: {
        id: number;
        name: string;
        /**
         * @description * `text2text` - Text to Text
         * * `text2image` - Text to Image
         * * `text2vector` - Text to Vector
         * @enum {string}
         */
        model_type?: "text2text" | "text2image" | "text2vector";
        model_provider?: ("openai" | "azure" | "anthropic" | "prem" | "groq" | "proxy-prem-ai") | "" | null;
        deprecated?: boolean;
      };
      session_id?: string | null;
      messages?: ({
          /**
           * @description * `user` - user
           * * `assistant` - assistant
           * * `system` - system
           * @enum {string}
           */
          role?: "user" | "assistant" | "system";
          content?: string;
        })[];
      feedback: ({
        positive: boolean;
        used_datapoint_messages: boolean;
        messages: ({
            /**
             * @description * `user` - user
             * * `assistant` - assistant
             * * `system` - system
             * @enum {string}
             */
            role?: "user" | "assistant" | "system";
            content?: string;
          })[];
      }) | null;
      document_chunks?: ({
          /** ID */
          document_id: number;
          content?: string | null;
        })[];
    };
    TraceRetrieveDocumentChunk: {
      /** ID */
      document_id: number;
      content?: string | null;
    };
    /**
     * @description * `function` - function
     * @enum {string}
     */
    TypeEnum: "function";
    UnprocessableEntityError: {
      message: string;
      /**
       * @description * `UnprocessableEntityError` - UnprocessableEntityError
       * @enum {string}
       */
      code: "UnprocessableEntityError";
    };
    /**
     * @description * `UnprocessableEntityError` - UnprocessableEntityError
     * @enum {string}
     */
    UnprocessableEntityErrorCodeEnum: "UnprocessableEntityError";
    Usage: {
      prompt_tokens: number;
      completion_tokens?: number;
      total_tokens: number;
    };
    ValidationDetail: {
      /** @description Error messages for the field. */
      error_messages: {
          [key: string]: unknown;
        }[];
    };
    ValidationError: {
      /** @description A description of the validation error. */
      message: string;
      /** @description Detailed information about the validation errors. */
      details: {
        [key: string]: {
          /** @description Error messages for the field. */
          error_messages: {
              [key: string]: unknown;
            }[];
        };
      };
      /**
       * @description * `ValidationError` - ValidationError
       * @enum {string}
       */
      code: "ValidationError";
    };
    /**
     * @description * `ValidationError` - ValidationError
     * @enum {string}
     */
    ValidationErrorCodeEnum: "ValidationError";
  };
  responses: never;
  parameters: never;
  requestBodies: never;
  headers: never;
  pathItems: never;
}

export type $defs = Record<string, never>;

export type external = Record<string, never>;

export interface operations {

  api_repositories_repositories_create: {
    requestBody: {
      content: {
        "application/json": {
          id: number;
          name: string;
          description?: string | null;
          organization: string;
        };
        "application/x-www-form-urlencoded": {
          id: number;
          name: string;
          description?: string | null;
          organization: string;
        };
        "multipart/form-data": {
          id: number;
          name: string;
          description?: string | null;
          organization: string;
        };
      };
    };
    responses: {
      201: {
        content: {
          "application/json": {
            id: number;
            name: string;
            description?: string | null;
            organization: string;
          };
        };
      };
    };
  };
  api_repositories_repository_document_create: {
    parameters: {
      path: {
        repository_id: number;
      };
    };
    requestBody: {
      content: {
        "multipart/form-data": {
          /** Format: uri */
          file: string;
        };
      };
    };
    responses: {
      201: {
        content: {
          "application/json": {
            repository_id: number;
            document_id: number;
            name: string;
            /**
             * @description * `pdf` - PDF
             * * `docx` - Word
             * * `txt` - Text
             * @enum {string}
             */
            document_type: "pdf" | "docx" | "txt";
            /**
             * @description * `PENDING` - Pending
             * * `UPLOADED` - Uploaded
             * * `INDEXING` - Indexing
             * * `COMPLETED` - Completed
             * * `FAILED` - Failed
             * @enum {string}
             */
            status: "PENDING" | "UPLOADED" | "INDEXING" | "COMPLETED" | "FAILED";
            error: string | null;
            /** @default 0 */
            chunk_count: number;
          };
        };
      };
    };
  };
  /** @description Creates a model response for the given chat conversation. Supports streaming with SSE, [documentation here](https://docs.premai.io/get-started/chat-completion-sse). */
  v1_chat_completions_create: {
    requestBody: {
      content: {
        "application/json": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The ID of the session to use. It helps to track the chat history. */
          session_id?: string;
          /** @description Options for Retrieval Augmented Generation (RAG). Will override launched model settings */
          repositories?: {
            /** @description The IDs of the repositories to use. */
            ids?: number[];
            limit?: number;
            /** Format: double */
            similarity_threshold?: number;
          };
          /** @description A list of messages comprising the conversation so far. */
          messages: ({
              /**
               * @description The role of the sender (e.g., 'user' or 'assistant').
               *
               * * `user` - user
               * * `assistant` - assistant
               */
              role: "user" | "assistant";
              /** @description The content of the message. */
              content?: OneOf<[string, ({
                  /** @enum {string} */
                  type: "text" | "image_url";
                  text?: string;
                  image_url?: {
                    url: string;
                  };
                })[]]>;
              /**
               * Format: uuid
               * @description The ID of the template to use.
               */
              template_id?: string;
              /** @description The parameters (key: value) to use with the given template. */
              params?: {
                [key: string]: unknown;
              };
            })[];
          /** @description ID of the model to use. See the model endpoint compatibility table for details. */
          model?: string;
          /** @description The system prompt to use. */
          system_prompt?: string;
          /** @description The maximum number of tokens to generate in the chat completion. */
          max_tokens?: number | null;
          /** @description If set, partial message deltas will be sent, like in ChatGPT. */
          stream?: boolean;
          /**
           * Format: double
           * @description What sampling temperature to use, between 0 and 2.
           * @default 1
           */
          temperature?: number;
          /** @description The tools to use in the completion. */
          tools?: {
              /**
               * @description * `function` - function
               * @enum {string}
               */
              type: "function";
              function: {
                name: string;
                description?: string;
                parameters: {
                  type: string;
                  properties: {
                    [key: string]: {
                      type: string;
                      description: string;
                    };
                  };
                  required: string[];
                };
              };
            }[] | null;
          /** @description The format of the response. Can be a JSON schema or a simple `json_object` type */
          response_format?: {
            [key: string]: unknown;
          } | null;
        };
        "application/x-www-form-urlencoded": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The ID of the session to use. It helps to track the chat history. */
          session_id?: string;
          /** @description Options for Retrieval Augmented Generation (RAG). Will override launched model settings */
          repositories?: {
            /** @description The IDs of the repositories to use. */
            ids?: number[];
            limit?: number;
            /** Format: double */
            similarity_threshold?: number;
          };
          /** @description A list of messages comprising the conversation so far. */
          messages: ({
              /**
               * @description The role of the sender (e.g., 'user' or 'assistant').
               *
               * * `user` - user
               * * `assistant` - assistant
               */
              role: "user" | "assistant";
              /** @description The content of the message. */
              content?: OneOf<[string, ({
                  /** @enum {string} */
                  type: "text" | "image_url";
                  text?: string;
                  image_url?: {
                    url: string;
                  };
                })[]]>;
              /**
               * Format: uuid
               * @description The ID of the template to use.
               */
              template_id?: string;
              /** @description The parameters (key: value) to use with the given template. */
              params?: {
                [key: string]: unknown;
              };
            })[];
          /** @description ID of the model to use. See the model endpoint compatibility table for details. */
          model?: string;
          /** @description The system prompt to use. */
          system_prompt?: string;
          /** @description The maximum number of tokens to generate in the chat completion. */
          max_tokens?: number | null;
          /** @description If set, partial message deltas will be sent, like in ChatGPT. */
          stream?: boolean;
          /**
           * Format: double
           * @description What sampling temperature to use, between 0 and 2.
           * @default 1
           */
          temperature?: number;
          /** @description The tools to use in the completion. */
          tools?: {
              /**
               * @description * `function` - function
               * @enum {string}
               */
              type: "function";
              function: {
                name: string;
                description?: string;
                parameters: {
                  type: string;
                  properties: {
                    [key: string]: {
                      type: string;
                      description: string;
                    };
                  };
                  required: string[];
                };
              };
            }[] | null;
          /** @description The format of the response. Can be a JSON schema or a simple `json_object` type */
          response_format?: {
            [key: string]: unknown;
          } | null;
        };
        "multipart/form-data": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The ID of the session to use. It helps to track the chat history. */
          session_id?: string;
          /** @description Options for Retrieval Augmented Generation (RAG). Will override launched model settings */
          repositories?: {
            /** @description The IDs of the repositories to use. */
            ids?: number[];
            limit?: number;
            /** Format: double */
            similarity_threshold?: number;
          };
          /** @description A list of messages comprising the conversation so far. */
          messages: ({
              /**
               * @description The role of the sender (e.g., 'user' or 'assistant').
               *
               * * `user` - user
               * * `assistant` - assistant
               */
              role: "user" | "assistant";
              /** @description The content of the message. */
              content?: OneOf<[string, ({
                  /** @enum {string} */
                  type: "text" | "image_url";
                  text?: string;
                  image_url?: {
                    url: string;
                  };
                })[]]>;
              /**
               * Format: uuid
               * @description The ID of the template to use.
               */
              template_id?: string;
              /** @description The parameters (key: value) to use with the given template. */
              params?: {
                [key: string]: unknown;
              };
            })[];
          /** @description ID of the model to use. See the model endpoint compatibility table for details. */
          model?: string;
          /** @description The system prompt to use. */
          system_prompt?: string;
          /** @description The maximum number of tokens to generate in the chat completion. */
          max_tokens?: number | null;
          /** @description If set, partial message deltas will be sent, like in ChatGPT. */
          stream?: boolean;
          /**
           * Format: double
           * @description What sampling temperature to use, between 0 and 2.
           * @default 1
           */
          temperature?: number;
          /** @description The tools to use in the completion. */
          tools?: {
              /**
               * @description * `function` - function
               * @enum {string}
               */
              type: "function";
              function: {
                name: string;
                description?: string;
                parameters: {
                  type: string;
                  properties: {
                    [key: string]: {
                      type: string;
                      description: string;
                    };
                  };
                  required: string[];
                };
              };
            }[] | null;
          /** @description The format of the response. Can be a JSON schema or a simple `json_object` type */
          response_format?: {
            [key: string]: unknown;
          } | null;
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            /** @description A list of chat completion choices. Can be more than one if n is greater than 1. */
            choices: ({
                /** @description The index of the choice in the list of choices. */
                index: number;
                /** @description The messages in the chat completion. */
                message: {
                  /**
                   * @description The role of the sender (e.g., 'user' or 'assistant').
                   *
                   * * `user` - user
                   * * `assistant` - assistant
                   */
                  role: "user" | "assistant";
                  /** @description The content of the message. */
                  content?: OneOf<[string, ({
                      /** @enum {string} */
                      type: "text" | "image_url";
                      text?: string;
                      image_url?: {
                        url: string;
                      };
                    })[]]>;
                  /**
                   * Format: uuid
                   * @description The ID of the template to use.
                   */
                  template_id?: string;
                  /** @description The parameters (key: value) to use with the given template. */
                  params?: {
                    [key: string]: unknown;
                  };
                };
                /** @description The reason the chat completion finished, e.g., 'stop' or 'length'. */
                finish_reason: string;
                /** @description The tool calls made. */
                tool_calls?: {
                    /**
                     * Format: uuid
                     * @description The ID of the tool call.
                     */
                    id: string;
                    /** @description The function called. */
                    function: {
                      /** @description The name of the function to be called. */
                      name: string;
                      /** @description The arguments passed to the function. */
                      arguments?: {
                        [key: string]: unknown;
                      };
                    };
                    /** @description The type of tool call. */
                    type: string;
                  }[] | null;
              })[];
            /** @description The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp. */
            created: number;
            /** @description The model to generate the completion. */
            model: string;
            /** @description The name of the provider that generated the completion. */
            provider_name: string;
            /** @description The ID of the provider that generated the completion. */
            provider_id: string;
            /** @description Chunks used to improve the completion */
            document_chunks?: {
                repository_id?: number;
                document_id?: number;
                chunk_id?: number;
                document_name?: string;
                /** Format: double */
                similarity_score?: number;
                content?: string;
              }[];
            /** @description The usage statistics for the completion. */
            usage: {
              prompt_tokens: number;
              completion_tokens?: number;
              total_tokens: number;
            };
            /**
             * Format: uuid
             * @description The trace ID of the completion.
             */
            trace_id: string;
          };
        };
      };
      400: {
        content: {
          "application/json": {
            /** @description A description of the validation error. */
            message: string;
            /** @description Detailed information about the validation errors. */
            details: {
              [key: string]: {
                /** @description Error messages for the field. */
                error_messages: {
                    [key: string]: unknown;
                  }[];
              };
            };
            /**
             * @description * `ValidationError` - ValidationError
             * @enum {string}
             */
            code: "ValidationError";
          };
        };
      };
      401: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `AuthenticationError` - AuthenticationError
             * @enum {string}
             */
            code: "AuthenticationError";
          };
        };
      };
      403: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `PermissionDeniedError` - PermissionDeniedError
             * @enum {string}
             */
            code: "PermissionDeniedError";
          };
        };
      };
      404: {
        content: {
          "application/json": OneOf<[{
            message: string;
            /**
             * @description * `ProviderNotFoundError` - ProviderNotFoundError
             * @enum {string}
             */
            code: "ProviderNotFoundError";
          }, {
            message: string;
            /**
             * @description * `ModelNotFoundError` - ModelNotFoundError
             * @enum {string}
             */
            code: "ModelNotFoundError";
          }]>;
        };
      };
      409: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ConflictError` - ConflictError
             * @enum {string}
             */
            code: "ConflictError";
          };
        };
      };
      422: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `UnprocessableEntityError` - UnprocessableEntityError
             * @enum {string}
             */
            code: "UnprocessableEntityError";
          };
        };
      };
      429: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `RateLimitError` - RateLimitError
             * @enum {string}
             */
            code: "RateLimitError";
          };
        };
      };
      500: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ProviderInternalServerError` - ProviderInternalServerError
             * @enum {string}
             */
            code: "ProviderInternalServerError";
          } | {
            message: string;
            /**
             * @description * `APIResponseValidationError` - APIResponseValidationError
             * @enum {string}
             */
            code: "APIResponseValidationError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
             * @enum {string}
             */
            code: "ProviderAPIStatusError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
             * @enum {string}
             */
            code: "ProviderAPITimeoutError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
             * @enum {string}
             */
            code: "ProviderAPIConnectionError";
          } | {
            message: string;
            /**
             * @description * `CatchAllError` - CatchAllError
             * @enum {string}
             */
            code: "CatchAllError";
          };
        };
      };
    };
  };
  /** @description Creates a finetuning job for the given project and model. */
  v1_create_finetuning_job_create: {
    requestBody: {
      content: {
        "application/json": {
          /** @description The id of the project to use for finetuning */
          project_id: number;
          /**
           * @description Name of the fine-tuning job
           * @default
           */
          name?: string;
          /** @description The slug of the base model to use for finetuning */
          base_model: string;
          /** @description The datapoints to use for finetuning */
          datapoints: ({
              messages: ({
                  /**
                   * @description * `user` - user
                   * * `assistant` - assistant
                   * * `system` - system
                   * @enum {string}
                   */
                  role?: "user" | "assistant" | "system";
                  content?: string;
                })[];
            })[];
          /** @description Hyperparameters for fine-tuning job */
          hyperparameters: {
            /** @description Batch size for fine-tuning */
            batch_size: number;
            /**
             * Format: double
             * @description Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.
             */
            learning_rate_multiplier: number;
            /** @description Number of epochs for fine-tuning */
            num_epochs: number;
          };
          /** @description Synthetic datageneration parameters for fine-tuning job */
          synthetic_datageneration_parameters: {
            /** @description Whether to run synthetic datageneration */
            run_synthetic_datageneration: boolean;
            /** @description Minimum number of datapoints required for fine-tuning */
            min_num_datapoints_for_ft: number;
            /**
             * Format: double
             * @description Temperature for synthetic datageneration
             */
            temperature: number;
            /** @description Positive instructions for synthetic datageneration, what the datapoints should be about */
            positive_instructions: string;
            /** @description Negative instructions for synthetic datageneration, what the datapoints should not be about */
            negative_instructions: string;
          };
        };
        "application/x-www-form-urlencoded": {
          /** @description The id of the project to use for finetuning */
          project_id: number;
          /**
           * @description Name of the fine-tuning job
           * @default
           */
          name?: string;
          /** @description The slug of the base model to use for finetuning */
          base_model: string;
          /** @description The datapoints to use for finetuning */
          datapoints: ({
              messages: ({
                  /**
                   * @description * `user` - user
                   * * `assistant` - assistant
                   * * `system` - system
                   * @enum {string}
                   */
                  role?: "user" | "assistant" | "system";
                  content?: string;
                })[];
            })[];
          /** @description Hyperparameters for fine-tuning job */
          hyperparameters: {
            /** @description Batch size for fine-tuning */
            batch_size: number;
            /**
             * Format: double
             * @description Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.
             */
            learning_rate_multiplier: number;
            /** @description Number of epochs for fine-tuning */
            num_epochs: number;
          };
          /** @description Synthetic datageneration parameters for fine-tuning job */
          synthetic_datageneration_parameters: {
            /** @description Whether to run synthetic datageneration */
            run_synthetic_datageneration: boolean;
            /** @description Minimum number of datapoints required for fine-tuning */
            min_num_datapoints_for_ft: number;
            /**
             * Format: double
             * @description Temperature for synthetic datageneration
             */
            temperature: number;
            /** @description Positive instructions for synthetic datageneration, what the datapoints should be about */
            positive_instructions: string;
            /** @description Negative instructions for synthetic datageneration, what the datapoints should not be about */
            negative_instructions: string;
          };
        };
        "multipart/form-data": {
          /** @description The id of the project to use for finetuning */
          project_id: number;
          /**
           * @description Name of the fine-tuning job
           * @default
           */
          name?: string;
          /** @description The slug of the base model to use for finetuning */
          base_model: string;
          /** @description The datapoints to use for finetuning */
          datapoints: ({
              messages: ({
                  /**
                   * @description * `user` - user
                   * * `assistant` - assistant
                   * * `system` - system
                   * @enum {string}
                   */
                  role?: "user" | "assistant" | "system";
                  content?: string;
                })[];
            })[];
          /** @description Hyperparameters for fine-tuning job */
          hyperparameters: {
            /** @description Batch size for fine-tuning */
            batch_size: number;
            /**
             * Format: double
             * @description Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.
             */
            learning_rate_multiplier: number;
            /** @description Number of epochs for fine-tuning */
            num_epochs: number;
          };
          /** @description Synthetic datageneration parameters for fine-tuning job */
          synthetic_datageneration_parameters: {
            /** @description Whether to run synthetic datageneration */
            run_synthetic_datageneration: boolean;
            /** @description Minimum number of datapoints required for fine-tuning */
            min_num_datapoints_for_ft: number;
            /**
             * Format: double
             * @description Temperature for synthetic datageneration
             */
            temperature: number;
            /** @description Positive instructions for synthetic datageneration, what the datapoints should be about */
            positive_instructions: string;
            /** @description Negative instructions for synthetic datageneration, what the datapoints should not be about */
            negative_instructions: string;
          };
        };
      };
    };
    responses: {
      201: {
        content: {
          "application/json": {
            successful: string;
            job_id: number;
            job_status: string;
          };
        };
      };
    };
  };
  /** @description Delete a finetuning job */
  v1_delete_finetuning_job_create: {
    requestBody: {
      content: {
        "application/json": {
          /** @description The ID of the project */
          project_id: number;
          /** @description The ID of the finetuning job to delete */
          fine_tuning_job_id: number;
        };
        "application/x-www-form-urlencoded": {
          /** @description The ID of the project */
          project_id: number;
          /** @description The ID of the finetuning job to delete */
          fine_tuning_job_id: number;
        };
        "multipart/form-data": {
          /** @description The ID of the project */
          project_id: number;
          /** @description The ID of the finetuning job to delete */
          fine_tuning_job_id: number;
        };
      };
    };
    responses: {
      /** @description No response body */
      200: {
        content: never;
      };
    };
  };
  /** @description Download a finetuned model */
  v1_download_finetuned_model_create: {
    requestBody: {
      content: {
        "application/json": {
          /** @description The ID of the project */
          project_id: number;
          /** @description The ID of the finetuned job to download */
          fine_tuning_job_id: number;
        };
        "application/x-www-form-urlencoded": {
          /** @description The ID of the project */
          project_id: number;
          /** @description The ID of the finetuned job to download */
          fine_tuning_job_id: number;
        };
        "multipart/form-data": {
          /** @description The ID of the project */
          project_id: number;
          /** @description The ID of the finetuned job to download */
          fine_tuning_job_id: number;
        };
      };
    };
    responses: {
      /** @description No response body */
      200: {
        content: never;
      };
    };
  };
  /** @description Creates embeddings for the given input. */
  v1_embeddings_create: {
    requestBody: {
      content: {
        "application/json": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The model to generate the embeddings. */
          model: string;
          /** @default float */
          encoding_format?: "float" | "base64";
          /** @description Embedding Input */
          input: string | string[] | number[] | number[][];
        };
        "application/x-www-form-urlencoded": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The model to generate the embeddings. */
          model: string;
          /** @default float */
          encoding_format?: "float" | "base64";
          /** @description Embedding Input */
          input: string | string[] | number[] | number[][];
        };
        "multipart/form-data": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The model to generate the embeddings. */
          model: string;
          /** @default float */
          encoding_format?: "float" | "base64";
          /** @description Embedding Input */
          input: string | string[] | number[] | number[][];
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            /** @description The embeddings for the input. */
            data: {
                /** @description The index of the token in the input. */
                index: number;
                /** @description The embedding for the input. */
                embedding: number[];
              }[];
            /** @description The model to generate the embeddings. */
            model: string;
            /** @description The usage statistics for the completion. */
            usage: {
              prompt_tokens: number;
              completion_tokens?: number;
              total_tokens: number;
            };
            /** @description The name of the provider that generated the completion. */
            provider_name: string;
            /** @description The ID of the provider that generated the completion. */
            provider_id: string;
          };
        };
      };
      400: {
        content: {
          "application/json": {
            /** @description A description of the validation error. */
            message: string;
            /** @description Detailed information about the validation errors. */
            details: {
              [key: string]: {
                /** @description Error messages for the field. */
                error_messages: {
                    [key: string]: unknown;
                  }[];
              };
            };
            /**
             * @description * `ValidationError` - ValidationError
             * @enum {string}
             */
            code: "ValidationError";
          };
        };
      };
      401: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `AuthenticationError` - AuthenticationError
             * @enum {string}
             */
            code: "AuthenticationError";
          };
        };
      };
      403: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `PermissionDeniedError` - PermissionDeniedError
             * @enum {string}
             */
            code: "PermissionDeniedError";
          };
        };
      };
      404: {
        content: {
          "application/json": OneOf<[{
            message: string;
            /**
             * @description * `ProviderNotFoundError` - ProviderNotFoundError
             * @enum {string}
             */
            code: "ProviderNotFoundError";
          }, {
            message: string;
            /**
             * @description * `ModelNotFoundError` - ModelNotFoundError
             * @enum {string}
             */
            code: "ModelNotFoundError";
          }]>;
        };
      };
      409: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ConflictError` - ConflictError
             * @enum {string}
             */
            code: "ConflictError";
          };
        };
      };
      422: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `UnprocessableEntityError` - UnprocessableEntityError
             * @enum {string}
             */
            code: "UnprocessableEntityError";
          };
        };
      };
      429: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `RateLimitError` - RateLimitError
             * @enum {string}
             */
            code: "RateLimitError";
          };
        };
      };
      500: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ProviderInternalServerError` - ProviderInternalServerError
             * @enum {string}
             */
            code: "ProviderInternalServerError";
          } | {
            message: string;
            /**
             * @description * `APIResponseValidationError` - APIResponseValidationError
             * @enum {string}
             */
            code: "APIResponseValidationError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
             * @enum {string}
             */
            code: "ProviderAPIStatusError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
             * @enum {string}
             */
            code: "ProviderAPITimeoutError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
             * @enum {string}
             */
            code: "ProviderAPIConnectionError";
          } | {
            message: string;
            /**
             * @description * `CatchAllError` - CatchAllError
             * @enum {string}
             */
            code: "CatchAllError";
          };
        };
      };
    };
  };
  /** @description Try out a finetuned model by creating a new playground */
  v1_finetuned_model_try_create: {
    requestBody: {
      content: {
        "application/json": {
          /** @description The ID of the finetuned model to try */
          model_id: number;
          /**
           * @description System prompt to use for the model
           * @default You are a helpful assistant.
           */
          system_prompt?: string;
          /** @description The ID of the project */
          project_id: number;
        };
        "application/x-www-form-urlencoded": {
          /** @description The ID of the finetuned model to try */
          model_id: number;
          /**
           * @description System prompt to use for the model
           * @default You are a helpful assistant.
           */
          system_prompt?: string;
          /** @description The ID of the project */
          project_id: number;
        };
        "multipart/form-data": {
          /** @description The ID of the finetuned model to try */
          model_id: number;
          /**
           * @description System prompt to use for the model
           * @default You are a helpful assistant.
           */
          system_prompt?: string;
          /** @description The ID of the project */
          project_id: number;
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            success: string;
            playground_url: string;
          };
        };
      };
      404: {
        content: {
          "application/json": {
            error?: string;
          };
        };
      };
    };
  };
  /** @description Get details for a fine-tuning job */
  v1_finetuning_job_details_create: {
    requestBody: {
      content: {
        "application/json": {
          project_id: number;
          fine_tuning_job_id: number;
        };
        "application/x-www-form-urlencoded": {
          project_id: number;
          fine_tuning_job_id: number;
        };
        "multipart/form-data": {
          project_id: number;
          fine_tuning_job_id: number;
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            name: string;
            baseModel: string;
            status: string;
            originalDataset: ({
                messages: ({
                    /**
                     * @description * `user` - user
                     * * `assistant` - assistant
                     * * `system` - system
                     * @enum {string}
                     */
                    role?: "user" | "assistant" | "system";
                    content?: string;
                  })[];
              })[];
            augmentedDataset: ({
                messages: ({
                    /**
                     * @description * `user` - user
                     * * `assistant` - assistant
                     * * `system` - system
                     * @enum {string}
                     */
                    role?: "user" | "assistant" | "system";
                    content?: string;
                  })[];
              })[];
            numTopics: number;
            numAugmentedDatapoints: number;
            /** Format: date-time */
            createdAt: string;
            evaluationScores?: {
              [key: string]: unknown;
            };
            finetunedModelId: number;
            id: number;
            providerJobId: string;
            hyperparameters: {
              /** @description Batch size for fine-tuning */
              batch_size: number;
              /**
               * Format: double
               * @description Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.
               */
              learning_rate_multiplier: number;
              /** @description Number of epochs for fine-tuning */
              num_epochs: number;
            };
            syntheticDatagenerationParameters: {
              /** @description Whether to run synthetic datageneration */
              run_synthetic_datageneration: boolean;
              /** @description Minimum number of datapoints required for fine-tuning */
              min_num_datapoints_for_ft: number;
              /**
               * Format: double
               * @description Temperature for synthetic datageneration
               */
              temperature: number;
              /** @description Positive instructions for synthetic datageneration, what the datapoints should be about */
              positive_instructions: string;
              /** @description Negative instructions for synthetic datageneration, what the datapoints should not be about */
              negative_instructions: string;
            };
            error?: {
              [key: string]: unknown;
            };
          };
        };
      };
      404: {
        content: {
          "application/json": {
            error?: string;
          };
        };
      };
    };
  };
  v1_get_dataset_retrieve: {
    responses: {
      /** @description No response body */
      200: {
        content: never;
      };
    };
  };
  /** @description Get initialization data for a project page */
  v1_init_page_data_create: {
    requestBody: {
      content: {
        "application/json": {
          project_id: number;
        };
        "application/x-www-form-urlencoded": {
          project_id: number;
        };
        "multipart/form-data": {
          project_id: number;
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            ftJobs: ({
                name: string;
                baseModel: string;
                status: string;
                originalDataset: ({
                    messages: ({
                        /**
                         * @description * `user` - user
                         * * `assistant` - assistant
                         * * `system` - system
                         * @enum {string}
                         */
                        role?: "user" | "assistant" | "system";
                        content?: string;
                      })[];
                  })[];
                augmentedDataset: ({
                    messages: ({
                        /**
                         * @description * `user` - user
                         * * `assistant` - assistant
                         * * `system` - system
                         * @enum {string}
                         */
                        role?: "user" | "assistant" | "system";
                        content?: string;
                      })[];
                  })[];
                numTopics: number;
                numAugmentedDatapoints: number;
                /** Format: date-time */
                createdAt: string;
                evaluationScores?: {
                  [key: string]: unknown;
                };
                finetunedModelId: number;
                id: number;
                providerJobId: string;
                hyperparameters: {
                  /** @description Batch size for fine-tuning */
                  batch_size: number;
                  /**
                   * Format: double
                   * @description Scaling factor for the learning rate. A smaller learning rate may be useful to avoid overfitting.
                   */
                  learning_rate_multiplier: number;
                  /** @description Number of epochs for fine-tuning */
                  num_epochs: number;
                };
                syntheticDatagenerationParameters: {
                  /** @description Whether to run synthetic datageneration */
                  run_synthetic_datageneration: boolean;
                  /** @description Minimum number of datapoints required for fine-tuning */
                  min_num_datapoints_for_ft: number;
                  /**
                   * Format: double
                   * @description Temperature for synthetic datageneration
                   */
                  temperature: number;
                  /** @description Positive instructions for synthetic datageneration, what the datapoints should be about */
                  positive_instructions: string;
                  /** @description Negative instructions for synthetic datageneration, what the datapoints should not be about */
                  negative_instructions: string;
                };
                error?: {
                  [key: string]: unknown;
                };
              })[];
          };
        };
      };
    };
  };
  v1_models_list: {
    responses: {
      200: {
        content: {
          "application/json": ({
              id: number;
              name: string;
              /**
               * @description * `text2text` - Text to Text
               * * `text2image` - Text to Image
               * * `text2vector` - Text to Vector
               * @enum {string}
               */
              model_type?: "text2text" | "text2image" | "text2vector";
              model_provider?: ("openai" | "azure" | "anthropic" | "prem" | "groq" | "proxy-prem-ai") | "" | null;
              deprecated?: boolean;
            })[];
        };
      };
    };
  };
  v1_models_retrieve: {
    parameters: {
      path: {
        /** @description A unique integer value identifying this Model. */
        id: number;
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            id: number;
            name: string;
            /**
             * @description * `text2text` - Text to Text
             * * `text2image` - Text to Image
             * * `text2vector` - Text to Vector
             * @enum {string}
             */
            model_type?: "text2text" | "text2image" | "text2vector";
            model_provider?: ("openai" | "azure" | "anthropic" | "prem" | "groq" | "proxy-prem-ai") | "" | null;
            deprecated?: boolean;
          };
        };
      };
    };
  };
  /** @description Set trace feedback */
  v1_set_trace_feedback_create: {
    requestBody?: {
      content: {
        "application/json": {
          feedback?: ({
            /** @default false */
            positive?: boolean;
            messages?: ({
                /**
                 * @description * `user` - user
                 * * `assistant` - assistant
                 * * `system` - system
                 * @enum {string}
                 */
                role?: "user" | "assistant" | "system";
                content?: string;
              })[];
          }) | null;
        };
        "application/x-www-form-urlencoded": {
          feedback?: ({
            /** @default false */
            positive?: boolean;
            messages?: ({
                /**
                 * @description * `user` - user
                 * * `assistant` - assistant
                 * * `system` - system
                 * @enum {string}
                 */
                role?: "user" | "assistant" | "system";
                content?: string;
              })[];
          }) | null;
        };
        "multipart/form-data": {
          feedback?: ({
            /** @default false */
            positive?: boolean;
            messages?: ({
                /**
                 * @description * `user` - user
                 * * `assistant` - assistant
                 * * `system` - system
                 * @enum {string}
                 */
                role?: "user" | "assistant" | "system";
                content?: string;
              })[];
          }) | null;
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            feedback?: ({
              /** @default false */
              positive?: boolean;
              messages?: ({
                  /**
                   * @description * `user` - user
                   * * `assistant` - assistant
                   * * `system` - system
                   * @enum {string}
                   */
                  role?: "user" | "assistant" | "system";
                  content?: string;
                })[];
            }) | null;
          };
        };
      };
    };
  };
  v1_traces_list: {
    parameters: {
      query: {
        admin_filter?: "ADMIN_ONLY";
        date_filter?: "last_day" | "last_hour" | "last_month" | "last_week" | "last_year";
        /** @description Format: YYYY/MM/DD */
        from_date?: string;
        project_id: number;
        search?: string;
        /** @description Sort field (-field for descending) */
        sort?: string;
        /** @description Format: YYYY/MM/DD */
        to_date?: string;
      };
    };
    responses: {
      200: {
        content: {
          "application/json": ({
              /** Format: uuid */
              trace_id: string;
              project_id: number;
              model_id: number;
              messages?: ({
                  /**
                   * @description * `user` - user
                   * * `assistant` - assistant
                   * * `system` - system
                   * @enum {string}
                   */
                  role?: "user" | "assistant" | "system";
                  content?: string;
                })[];
              feedback: ({
                positive: boolean;
                used_datapoint_messages: boolean;
                messages: ({
                    /**
                     * @description * `user` - user
                     * * `assistant` - assistant
                     * * `system` - system
                     * @enum {string}
                     */
                    role?: "user" | "assistant" | "system";
                    content?: string;
                  })[];
              }) | null;
            })[];
        };
      };
    };
  };
  v1_traces_retrieve: {
    parameters: {
      path: {
        /** @description A UUID string identifying this Trace. */
        id: string;
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            /** Format: uuid */
            trace_id: string;
            project: {
              /** ID */
              project_id: number;
              name: string;
              description?: string | null;
            };
            model: {
              id: number;
              name: string;
              /**
               * @description * `text2text` - Text to Text
               * * `text2image` - Text to Image
               * * `text2vector` - Text to Vector
               * @enum {string}
               */
              model_type?: "text2text" | "text2image" | "text2vector";
              model_provider?: ("openai" | "azure" | "anthropic" | "prem" | "groq" | "proxy-prem-ai") | "" | null;
              deprecated?: boolean;
            };
            session_id?: string | null;
            messages?: ({
                /**
                 * @description * `user` - user
                 * * `assistant` - assistant
                 * * `system` - system
                 * @enum {string}
                 */
                role?: "user" | "assistant" | "system";
                content?: string;
              })[];
            feedback: ({
              positive: boolean;
              used_datapoint_messages: boolean;
              messages: ({
                  /**
                   * @description * `user` - user
                   * * `assistant` - assistant
                   * * `system` - system
                   * @enum {string}
                   */
                  role?: "user" | "assistant" | "system";
                  content?: string;
                })[];
            }) | null;
            document_chunks?: ({
                /** ID */
                document_id: number;
                content?: string | null;
              })[];
          };
        };
      };
    };
  };
}
