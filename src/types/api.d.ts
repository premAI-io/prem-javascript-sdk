/**
 * This file was auto-generated by openapi-typescript.
 * Do not make direct changes to the file.
 */


/** OneOf type helpers */
type Without<T, U> = { [P in Exclude<keyof T, keyof U>]?: never };
type XOR<T, U> = (T | U) extends object ? (Without<T, U> & U) | (Without<U, T> & T) : T | U;
type OneOf<T extends any[]> = T extends [infer Only] ? Only : T extends [infer A, infer B, ...infer Rest] ? OneOf<[XOR<A, B>, ...Rest]> : never;

export interface paths {
  "/v1/chat/completions": {
    /** @description Creates a model response for the given chat conversation. Supports streaming with SSE, [documentation here](https://docs.premai.io/get-started/chat-completion-sse). */
    post: operations["v1_chat_completions_create"];
  };
  "/v1/data-points/": {
    get: operations["v1_data_points_list"];
    post: operations["v1_data_points_create"];
  };
  "/v1/data-points/{id}/": {
    get: operations["v1_data_points_retrieve"];
    put: operations["v1_data_points_update"];
    delete: operations["v1_data_points_destroy"];
    patch: operations["v1_data_points_partial_update"];
  };
  "/v1/embeddings": {
    /** @description Creates embeddings for the given input. */
    post: operations["v1_embeddings_create"];
  };
  "/v1/finetuning": {
    /** @description Creates a finetuning job. */
    post: operations["v1_finetuning_create"];
  };
  "/v1/finetuning/{job_id}": {
    /** @description Retrieve a finetuning job. */
    get: operations["v1_finetuning_retrieve"];
  };
  "/v1/models/": {
    get: operations["v1_models_list"];
  };
  "/v1/models/{id}/": {
    get: operations["v1_models_retrieve"];
  };
  "/v1/repository/{repository_id}/document": {
    post: operations["v1_repository_document_create"];
  };
}

export type webhooks = Record<string, never>;

export interface components {
  schemas: {
    APIResponseValidationError: {
      message: string;
      /**
       * @description * `APIResponseValidationError` - APIResponseValidationError
       * @enum {string}
       */
      code: "APIResponseValidationError";
    };
    /**
     * @description * `APIResponseValidationError` - APIResponseValidationError
     * @enum {string}
     */
    APIResponseValidationErrorCodeEnum: "APIResponseValidationError";
    AuthenticationError: {
      message: string;
      /**
       * @description * `AuthenticationError` - AuthenticationError
       * @enum {string}
       */
      code: "AuthenticationError";
    };
    /**
     * @description * `AuthenticationError` - AuthenticationError
     * @enum {string}
     */
    AuthenticationErrorCodeEnum: "AuthenticationError";
    /** @enum {unknown} */
    BlankEnum: "";
    CatchAllError: {
      message: string;
      /**
       * @description * `CatchAllError` - CatchAllError
       * @enum {string}
       */
      code: "CatchAllError";
    };
    /**
     * @description * `CatchAllError` - CatchAllError
     * @enum {string}
     */
    CatchAllErrorCodeEnum: "CatchAllError";
    ChatCompletionInput: {
      /** @description The ID of the project to use. */
      project_id: number;
      /** @description The ID of the session to use. It helps to track the chat history. */
      session_id?: string;
      /** @description Options for Retrieval Augmented Generation (RAG). Will override launched model settings */
      repositories?: {
        /** @description The IDs of the repositories to use. */
        ids?: number[];
        limit?: number;
        /** Format: double */
        similarity_threshold?: number;
      };
      /** @description A list of messages comprising the conversation so far. */
      messages: ({
          /**
           * @description The role of the sender (e.g., 'user' or 'assistant').
           *
           * * `user` - user
           * * `assistant` - assistant
           */
          role: "user" | "assistant";
          /** @description The content of the message. */
          content: string;
        })[];
      /** @description ID of the model to use. See the model endpoint compatibility table for details. */
      model?: string;
      /** @description The system prompt to use. */
      system_prompt?: string;
      /**
       * Format: double
       * @description Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency.
       */
      frequency_penalty?: number;
      /** @description JSON object that maps tokens to an associated bias value from -100 to 100. */
      logit_bias?: {
        [key: string]: unknown;
      } | null;
      /** @description The maximum number of tokens to generate in the chat completion. */
      max_tokens?: number | null;
      /**
       * Format: double
       * @description Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far.
       */
      presence_penalty?: number;
      /** @description An object specifying the format that the model must output. */
      response_format?: {
        [key: string]: unknown;
      } | null;
      /** @description This feature is in Beta. If specified, our system will make a best effort to sample deterministically. */
      seed?: number | null;
      /** @description Up to 4 sequences where the API will stop generating further tokens. */
      stop?: string | null;
      /** @description If set, partial message deltas will be sent, like in ChatGPT. */
      stream?: boolean;
      /**
       * Format: double
       * @description What sampling temperature to use, between 0 and 2.
       */
      temperature?: number | null;
      /**
       * Format: double
       * @description An alternative to sampling with temperature, called nucleus sampling.
       */
      top_p?: number | null;
      /** @description A list of tools the model may call. Currently, only functions are supported as a tool. */
      tools?: {
          [key: string]: unknown;
        }[];
      /** @description A unique identifier representing your end-user. */
      user?: string | null;
    };
    ChatCompletionResponse: {
      /** @description A list of chat completion choices. Can be more than one if n is greater than 1. */
      choices: ({
          /** @description The index of the choice in the list of choices. */
          index: number;
          /** @description The messages in the chat completion. */
          message: {
            /**
             * @description The role of the sender (e.g., 'user' or 'assistant').
             *
             * * `user` - user
             * * `assistant` - assistant
             */
            role: "user" | "assistant";
            /** @description The content of the message. */
            content: string;
          };
          /** @description The reason the chat completion finished, e.g., 'stop' or 'length'. */
          finish_reason: string;
        })[];
      /** @description The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp. */
      created: number;
      /** @description The model to generate the completion. */
      model: string;
      /** @description The name of the provider that generated the completion. */
      provider_name: string;
      /** @description The ID of the provider that generated the completion. */
      provider_id: string;
      /** @description Chunks used to improve the completion */
      document_chunks?: {
          repository_id?: number;
          document_id?: number;
          chunk_id?: number;
          document_name?: string;
          /** Format: double */
          similarity_score?: number;
          content?: string;
        }[];
      /** @description The usage statistics for the completion. */
      usage: {
        prompt_tokens: number;
        completion_tokens?: number;
        total_tokens: number;
      };
      /**
       * Format: uuid
       * @description The trace ID of the completion.
       */
      trace_id: string;
    };
    ConflictError: {
      message: string;
      /**
       * @description * `ConflictError` - ConflictError
       * @enum {string}
       */
      code: "ConflictError";
    };
    /**
     * @description * `ConflictError` - ConflictError
     * @enum {string}
     */
    ConflictErrorCodeEnum: "ConflictError";
    DataPoint: {
      id: number;
      /** Format: date-time */
      created_at: string;
      /** Format: date-time */
      updated_at: string;
      input?: string | null;
      output?: string | null;
      positive: boolean;
      /** Format: uuid */
      trace?: string | null;
    };
    DocumentChunks: {
      repository_id?: number;
      document_id?: number;
      chunk_id?: number;
      document_name?: string;
      /** Format: double */
      similarity_score?: number;
      content?: string;
    };
    DocumentInput: {
      name: string;
      content: string;
      /**
       * @description * `pdf` - PDF
       * * `docx` - Word
       * * `txt` - Text
       * @enum {string}
       */
      document_type: "pdf" | "docx" | "txt";
    };
    DocumentOutput: {
      repository_id: number;
      document_id: number;
      name: string;
      /**
       * @description * `pdf` - PDF
       * * `docx` - Word
       * * `txt` - Text
       * @enum {string}
       */
      document_type: "pdf" | "docx" | "txt";
      /**
       * @description * `PENDING` - Pending
       * * `UPLOADED` - Uploaded
       * * `PARSING` - Parsing
       * * `CHUNKING` - Chunking
       * * `WAITING_FOR_CHUNKS_COMPLETION` - Waiting for chunks completion
       * * `PROCESSING` - Processing
       * * `COMPLETED` - Completed
       * * `FAILED` - Failed
       * @enum {string}
       */
      status: "PENDING" | "UPLOADED" | "PARSING" | "CHUNKING" | "WAITING_FOR_CHUNKS_COMPLETION" | "PROCESSING" | "COMPLETED" | "FAILED";
      error: string | null;
      /** @default 0 */
      chunk_count: number;
    };
    /**
     * @description * `pdf` - PDF
     * * `docx` - Word
     * * `txt` - Text
     * @enum {string}
     */
    DocumentTypeEnum: "pdf" | "docx" | "txt";
    Embedding: {
      /** @description The index of the token in the input. */
      index: number;
      /** @description The embedding for the input. */
      embedding: number[];
    };
    EmbeddingsInput: {
      /** @description The ID of the project to use. */
      project_id: number;
      /** @description The model to generate the embeddings. */
      model: string;
      /** @default float */
      encoding_format?: "float" | "base64";
      /** @description Embedding Input */
      input: string | string[] | number[] | number[][];
    };
    EmbeddingsResponse: {
      /** @description The embeddings for the input. */
      data: {
          /** @description The index of the token in the input. */
          index: number;
          /** @description The embedding for the input. */
          embedding: number[];
        }[];
      /** @description The model to generate the embeddings. */
      model: string;
      /** @description The usage statistics for the completion. */
      usage: {
        prompt_tokens: number;
        completion_tokens?: number;
        total_tokens: number;
      };
      /** @description The name of the provider that generated the completion. */
      provider_name: string;
      /** @description The ID of the provider that generated the completion. */
      provider_id: string;
    };
    /**
     * @description * `float` - float
     * * `base64` - base64
     * @enum {string}
     */
    EncodingFormatEnum: "float" | "base64";
    Enhancement: {
      /** @description The IDs of the repositories to use. */
      ids?: number[];
      limit?: number;
      /** Format: double */
      similarity_threshold?: number;
    };
    FineTuningInput: {
      /** @description The ID of the project to use. */
      project_id: number;
      /** @description ID of the model to use. See the model endpoint compatibility table for details. */
      model?: string;
      /** @description The training file. */
      training_data: {
          /** @description The input text. */
          input: string;
          /** @description The output text. */
          output: string;
        }[];
      /** @description The training file. */
      validaton_data?: {
          /** @description The input text. */
          input: string;
          /** @description The output text. */
          output: string;
        }[];
      /**
       * @description The number of epochs to train for.
       * @default 1
       */
      num_epochs?: number;
    };
    FineTuningResponse: {
      /** @description The ID of the fine-tuning job. */
      job_id: string;
    };
    FineTuningSample: {
      /** @description The input text. */
      input: string;
      /** @description The output text. */
      output: string;
    };
    InputDataPoint: {
      input?: string | null;
      output?: string | null;
      positive: boolean;
      trace?: string | null;
      project: number;
    };
    InternalServerError: {
      message: string;
      /**
       * @description * `ProviderInternalServerError` - ProviderInternalServerError
       * @enum {string}
       */
      code: "ProviderInternalServerError";
    } | {
      message: string;
      /**
       * @description * `APIResponseValidationError` - APIResponseValidationError
       * @enum {string}
       */
      code: "APIResponseValidationError";
    } | {
      message: string;
      /**
       * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
       * @enum {string}
       */
      code: "ProviderAPIStatusError";
    } | {
      message: string;
      /**
       * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
       * @enum {string}
       */
      code: "ProviderAPITimeoutError";
    } | {
      message: string;
      /**
       * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
       * @enum {string}
       */
      code: "ProviderAPIConnectionError";
    } | {
      message: string;
      /**
       * @description * `CatchAllError` - CatchAllError
       * @enum {string}
       */
      code: "CatchAllError";
    };
    Message: {
      /**
       * @description The role of the sender (e.g., 'user' or 'assistant').
       *
       * * `user` - user
       * * `assistant` - assistant
       */
      role: "user" | "assistant";
      /** @description The content of the message. */
      content: string;
    };
    Model: {
      id: number;
      name: string;
      /**
       * @description * `text2text` - Text to Text
       * * `text2image` - Text to Image
       * * `text2vector` - Text to Vector
       * @enum {string}
       */
      model_type?: "text2text" | "text2image" | "text2vector";
      model_provider?: ("openai" | "azure" | "azure-mistral" | "cohere" | "anthropic" | "cloudflare" | "deepinfra" | "lamini" | "octoai" | "replicate" | "together" | "fireworksai" | "mistralai" | "prem" | "anyscale" | "openrouter" | "perplexity" | "groq") | "" | null;
    };
    ModelNotFoundError: {
      message: string;
      /**
       * @description * `ModelNotFoundError` - ModelNotFoundError
       * @enum {string}
       */
      code: "ModelNotFoundError";
    };
    /**
     * @description * `ModelNotFoundError` - ModelNotFoundError
     * @enum {string}
     */
    ModelNotFoundErrorCodeEnum: "ModelNotFoundError";
    /**
     * @description * `openai` - OpenAI
     * * `azure` - Azure OpenAI
     * * `azure-mistral` - Azure Mistral
     * * `cohere` - Cohere
     * * `anthropic` - Anthropic
     * * `cloudflare` - Cloudflare
     * * `deepinfra` - Deep Infra
     * * `lamini` - Lamini
     * * `octoai` - Octo AI
     * * `replicate` - Replicate
     * * `together` - Together
     * * `fireworksai` - Fireworks AI
     * * `mistralai` - Mistral AI
     * * `prem` - Prem AI
     * * `anyscale` - Anyscale
     * * `openrouter` - Open Router
     * * `perplexity` - Perplexity
     * * `groq` - Groq
     * @enum {string}
     */
    ModelProviderEnum: "openai" | "azure" | "azure-mistral" | "cohere" | "anthropic" | "cloudflare" | "deepinfra" | "lamini" | "octoai" | "replicate" | "together" | "fireworksai" | "mistralai" | "prem" | "anyscale" | "openrouter" | "perplexity" | "groq";
    /**
     * @description * `text2text` - Text to Text
     * * `text2image` - Text to Image
     * * `text2vector` - Text to Vector
     * @enum {string}
     */
    ModelTypeEnum: "text2text" | "text2image" | "text2vector";
    NotFoundError: OneOf<[{
      message: string;
      /**
       * @description * `ProviderNotFoundError` - ProviderNotFoundError
       * @enum {string}
       */
      code: "ProviderNotFoundError";
    }, {
      message: string;
      /**
       * @description * `ModelNotFoundError` - ModelNotFoundError
       * @enum {string}
       */
      code: "ModelNotFoundError";
    }]>;
    /** @enum {unknown} */
    NullEnum: "";
    PatchedDataPoint: {
      id?: number;
      /** Format: date-time */
      created_at?: string;
      /** Format: date-time */
      updated_at?: string;
      input?: string | null;
      output?: string | null;
      positive?: boolean;
      /** Format: uuid */
      trace?: string | null;
    };
    PermissionDeniedError: {
      message: string;
      /**
       * @description * `PermissionDeniedError` - PermissionDeniedError
       * @enum {string}
       */
      code: "PermissionDeniedError";
    };
    /**
     * @description * `PermissionDeniedError` - PermissionDeniedError
     * @enum {string}
     */
    PermissionDeniedErrorCodeEnum: "PermissionDeniedError";
    ProviderAPIConnectionError: {
      message: string;
      /**
       * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
       * @enum {string}
       */
      code: "ProviderAPIConnectionError";
    };
    /**
     * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
     * @enum {string}
     */
    ProviderAPIConnectionErrorCodeEnum: "ProviderAPIConnectionError";
    ProviderAPIStatusError: {
      message: string;
      /**
       * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
       * @enum {string}
       */
      code: "ProviderAPIStatusError";
    };
    /**
     * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
     * @enum {string}
     */
    ProviderAPIStatusErrorCodeEnum: "ProviderAPIStatusError";
    ProviderAPITimeoutError: {
      message: string;
      /**
       * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
       * @enum {string}
       */
      code: "ProviderAPITimeoutError";
    };
    /**
     * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
     * @enum {string}
     */
    ProviderAPITimeoutErrorCodeEnum: "ProviderAPITimeoutError";
    ProviderInternalServerError: {
      message: string;
      /**
       * @description * `ProviderInternalServerError` - ProviderInternalServerError
       * @enum {string}
       */
      code: "ProviderInternalServerError";
    };
    /**
     * @description * `ProviderInternalServerError` - ProviderInternalServerError
     * @enum {string}
     */
    ProviderInternalServerErrorCodeEnum: "ProviderInternalServerError";
    ProviderNotFoundError: {
      message: string;
      /**
       * @description * `ProviderNotFoundError` - ProviderNotFoundError
       * @enum {string}
       */
      code: "ProviderNotFoundError";
    };
    /**
     * @description * `ProviderNotFoundError` - ProviderNotFoundError
     * @enum {string}
     */
    ProviderNotFoundErrorCodeEnum: "ProviderNotFoundError";
    RateLimitError: {
      message: string;
      /**
       * @description * `RateLimitError` - RateLimitError
       * @enum {string}
       */
      code: "RateLimitError";
    };
    /**
     * @description * `RateLimitError` - RateLimitError
     * @enum {string}
     */
    RateLimitErrorCodeEnum: "RateLimitError";
    ResponseChoice: {
      /** @description The index of the choice in the list of choices. */
      index: number;
      /** @description The messages in the chat completion. */
      message: {
        /**
         * @description The role of the sender (e.g., 'user' or 'assistant').
         *
         * * `user` - user
         * * `assistant` - assistant
         */
        role: "user" | "assistant";
        /** @description The content of the message. */
        content: string;
      };
      /** @description The reason the chat completion finished, e.g., 'stop' or 'length'. */
      finish_reason: string;
    };
    RetrieveFineTuningResponse: {
      /** @description The ID of the fine-tuning job. */
      id: string;
      /** @description The ID of the fine-tuned model. */
      fine_tuned_model: string;
      /** @description The Unix timestamp (in seconds) of when the fine-tuning job was created. */
      created_at: number;
      /** @description The Unix timestamp (in seconds) of when the fine-tuning job was finished. */
      finished_at?: number;
      /** @description The status of the fine-tuning job. */
      status: string;
      /** @description The error message of the fine-tuning job. */
      error?: string;
      /** @description The name of the provider that generated the completion. */
      provider_name: string;
      /** @description The ID of the provider that generated the completion. */
      provider_id: string;
      /** @description The status code of the fine-tuning job. */
      status_code: number;
    };
    /**
     * @description * `user` - user
     * * `assistant` - assistant
     * @enum {string}
     */
    RoleEnum: "user" | "assistant";
    /**
     * @description * `PENDING` - Pending
     * * `UPLOADED` - Uploaded
     * * `PARSING` - Parsing
     * * `CHUNKING` - Chunking
     * * `WAITING_FOR_CHUNKS_COMPLETION` - Waiting for chunks completion
     * * `PROCESSING` - Processing
     * * `COMPLETED` - Completed
     * * `FAILED` - Failed
     * @enum {string}
     */
    StatusEnum: "PENDING" | "UPLOADED" | "PARSING" | "CHUNKING" | "WAITING_FOR_CHUNKS_COMPLETION" | "PROCESSING" | "COMPLETED" | "FAILED";
    UnprocessableEntityError: {
      message: string;
      /**
       * @description * `UnprocessableEntityError` - UnprocessableEntityError
       * @enum {string}
       */
      code: "UnprocessableEntityError";
    };
    /**
     * @description * `UnprocessableEntityError` - UnprocessableEntityError
     * @enum {string}
     */
    UnprocessableEntityErrorCodeEnum: "UnprocessableEntityError";
    Usage: {
      prompt_tokens: number;
      completion_tokens?: number;
      total_tokens: number;
    };
    ValidationDetail: {
      /** @description Error messages for the field. */
      error_messages: {
          [key: string]: unknown;
        }[];
    };
    ValidationError: {
      /** @description A description of the validation error. */
      message: string;
      /** @description Detailed information about the validation errors. */
      details: {
        [key: string]: {
          /** @description Error messages for the field. */
          error_messages: {
              [key: string]: unknown;
            }[];
        };
      };
      /**
       * @description * `ValidationError` - ValidationError
       * @enum {string}
       */
      code: "ValidationError";
    };
    /**
     * @description * `ValidationError` - ValidationError
     * @enum {string}
     */
    ValidationErrorCodeEnum: "ValidationError";
  };
  responses: never;
  parameters: never;
  requestBodies: never;
  headers: never;
  pathItems: never;
}

export type $defs = Record<string, never>;

export type external = Record<string, never>;

export interface operations {

  /** @description Creates a model response for the given chat conversation. Supports streaming with SSE, [documentation here](https://docs.premai.io/get-started/chat-completion-sse). */
  v1_chat_completions_create: {
    requestBody: {
      content: {
        "application/json": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The ID of the session to use. It helps to track the chat history. */
          session_id?: string;
          /** @description Options for Retrieval Augmented Generation (RAG). Will override launched model settings */
          repositories?: {
            /** @description The IDs of the repositories to use. */
            ids?: number[];
            limit?: number;
            /** Format: double */
            similarity_threshold?: number;
          };
          /** @description A list of messages comprising the conversation so far. */
          messages: ({
              /**
               * @description The role of the sender (e.g., 'user' or 'assistant').
               *
               * * `user` - user
               * * `assistant` - assistant
               */
              role: "user" | "assistant";
              /** @description The content of the message. */
              content: string;
            })[];
          /** @description ID of the model to use. See the model endpoint compatibility table for details. */
          model?: string;
          /** @description The system prompt to use. */
          system_prompt?: string;
          /**
           * Format: double
           * @description Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency.
           */
          frequency_penalty?: number;
          /** @description JSON object that maps tokens to an associated bias value from -100 to 100. */
          logit_bias?: {
            [key: string]: unknown;
          } | null;
          /** @description The maximum number of tokens to generate in the chat completion. */
          max_tokens?: number | null;
          /**
           * Format: double
           * @description Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far.
           */
          presence_penalty?: number;
          /** @description An object specifying the format that the model must output. */
          response_format?: {
            [key: string]: unknown;
          } | null;
          /** @description This feature is in Beta. If specified, our system will make a best effort to sample deterministically. */
          seed?: number | null;
          /** @description Up to 4 sequences where the API will stop generating further tokens. */
          stop?: string | null;
          /** @description If set, partial message deltas will be sent, like in ChatGPT. */
          stream?: boolean;
          /**
           * Format: double
           * @description What sampling temperature to use, between 0 and 2.
           */
          temperature?: number | null;
          /**
           * Format: double
           * @description An alternative to sampling with temperature, called nucleus sampling.
           */
          top_p?: number | null;
          /** @description A list of tools the model may call. Currently, only functions are supported as a tool. */
          tools?: {
              [key: string]: unknown;
            }[];
          /** @description A unique identifier representing your end-user. */
          user?: string | null;
        };
        "application/x-www-form-urlencoded": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The ID of the session to use. It helps to track the chat history. */
          session_id?: string;
          /** @description Options for Retrieval Augmented Generation (RAG). Will override launched model settings */
          repositories?: {
            /** @description The IDs of the repositories to use. */
            ids?: number[];
            limit?: number;
            /** Format: double */
            similarity_threshold?: number;
          };
          /** @description A list of messages comprising the conversation so far. */
          messages: ({
              /**
               * @description The role of the sender (e.g., 'user' or 'assistant').
               *
               * * `user` - user
               * * `assistant` - assistant
               */
              role: "user" | "assistant";
              /** @description The content of the message. */
              content: string;
            })[];
          /** @description ID of the model to use. See the model endpoint compatibility table for details. */
          model?: string;
          /** @description The system prompt to use. */
          system_prompt?: string;
          /**
           * Format: double
           * @description Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency.
           */
          frequency_penalty?: number;
          /** @description JSON object that maps tokens to an associated bias value from -100 to 100. */
          logit_bias?: {
            [key: string]: unknown;
          } | null;
          /** @description The maximum number of tokens to generate in the chat completion. */
          max_tokens?: number | null;
          /**
           * Format: double
           * @description Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far.
           */
          presence_penalty?: number;
          /** @description An object specifying the format that the model must output. */
          response_format?: {
            [key: string]: unknown;
          } | null;
          /** @description This feature is in Beta. If specified, our system will make a best effort to sample deterministically. */
          seed?: number | null;
          /** @description Up to 4 sequences where the API will stop generating further tokens. */
          stop?: string | null;
          /** @description If set, partial message deltas will be sent, like in ChatGPT. */
          stream?: boolean;
          /**
           * Format: double
           * @description What sampling temperature to use, between 0 and 2.
           */
          temperature?: number | null;
          /**
           * Format: double
           * @description An alternative to sampling with temperature, called nucleus sampling.
           */
          top_p?: number | null;
          /** @description A list of tools the model may call. Currently, only functions are supported as a tool. */
          tools?: {
              [key: string]: unknown;
            }[];
          /** @description A unique identifier representing your end-user. */
          user?: string | null;
        };
        "multipart/form-data": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The ID of the session to use. It helps to track the chat history. */
          session_id?: string;
          /** @description Options for Retrieval Augmented Generation (RAG). Will override launched model settings */
          repositories?: {
            /** @description The IDs of the repositories to use. */
            ids?: number[];
            limit?: number;
            /** Format: double */
            similarity_threshold?: number;
          };
          /** @description A list of messages comprising the conversation so far. */
          messages: ({
              /**
               * @description The role of the sender (e.g., 'user' or 'assistant').
               *
               * * `user` - user
               * * `assistant` - assistant
               */
              role: "user" | "assistant";
              /** @description The content of the message. */
              content: string;
            })[];
          /** @description ID of the model to use. See the model endpoint compatibility table for details. */
          model?: string;
          /** @description The system prompt to use. */
          system_prompt?: string;
          /**
           * Format: double
           * @description Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency.
           */
          frequency_penalty?: number;
          /** @description JSON object that maps tokens to an associated bias value from -100 to 100. */
          logit_bias?: {
            [key: string]: unknown;
          } | null;
          /** @description The maximum number of tokens to generate in the chat completion. */
          max_tokens?: number | null;
          /**
           * Format: double
           * @description Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far.
           */
          presence_penalty?: number;
          /** @description An object specifying the format that the model must output. */
          response_format?: {
            [key: string]: unknown;
          } | null;
          /** @description This feature is in Beta. If specified, our system will make a best effort to sample deterministically. */
          seed?: number | null;
          /** @description Up to 4 sequences where the API will stop generating further tokens. */
          stop?: string | null;
          /** @description If set, partial message deltas will be sent, like in ChatGPT. */
          stream?: boolean;
          /**
           * Format: double
           * @description What sampling temperature to use, between 0 and 2.
           */
          temperature?: number | null;
          /**
           * Format: double
           * @description An alternative to sampling with temperature, called nucleus sampling.
           */
          top_p?: number | null;
          /** @description A list of tools the model may call. Currently, only functions are supported as a tool. */
          tools?: {
              [key: string]: unknown;
            }[];
          /** @description A unique identifier representing your end-user. */
          user?: string | null;
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            /** @description A list of chat completion choices. Can be more than one if n is greater than 1. */
            choices: ({
                /** @description The index of the choice in the list of choices. */
                index: number;
                /** @description The messages in the chat completion. */
                message: {
                  /**
                   * @description The role of the sender (e.g., 'user' or 'assistant').
                   *
                   * * `user` - user
                   * * `assistant` - assistant
                   */
                  role: "user" | "assistant";
                  /** @description The content of the message. */
                  content: string;
                };
                /** @description The reason the chat completion finished, e.g., 'stop' or 'length'. */
                finish_reason: string;
              })[];
            /** @description The Unix timestamp (in seconds) of when the chat completion was created. Each chunk has the same timestamp. */
            created: number;
            /** @description The model to generate the completion. */
            model: string;
            /** @description The name of the provider that generated the completion. */
            provider_name: string;
            /** @description The ID of the provider that generated the completion. */
            provider_id: string;
            /** @description Chunks used to improve the completion */
            document_chunks?: {
                repository_id?: number;
                document_id?: number;
                chunk_id?: number;
                document_name?: string;
                /** Format: double */
                similarity_score?: number;
                content?: string;
              }[];
            /** @description The usage statistics for the completion. */
            usage: {
              prompt_tokens: number;
              completion_tokens?: number;
              total_tokens: number;
            };
            /**
             * Format: uuid
             * @description The trace ID of the completion.
             */
            trace_id: string;
          };
        };
      };
      400: {
        content: {
          "application/json": {
            /** @description A description of the validation error. */
            message: string;
            /** @description Detailed information about the validation errors. */
            details: {
              [key: string]: {
                /** @description Error messages for the field. */
                error_messages: {
                    [key: string]: unknown;
                  }[];
              };
            };
            /**
             * @description * `ValidationError` - ValidationError
             * @enum {string}
             */
            code: "ValidationError";
          };
        };
      };
      401: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `AuthenticationError` - AuthenticationError
             * @enum {string}
             */
            code: "AuthenticationError";
          };
        };
      };
      403: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `PermissionDeniedError` - PermissionDeniedError
             * @enum {string}
             */
            code: "PermissionDeniedError";
          };
        };
      };
      404: {
        content: {
          "application/json": OneOf<[{
            message: string;
            /**
             * @description * `ProviderNotFoundError` - ProviderNotFoundError
             * @enum {string}
             */
            code: "ProviderNotFoundError";
          }, {
            message: string;
            /**
             * @description * `ModelNotFoundError` - ModelNotFoundError
             * @enum {string}
             */
            code: "ModelNotFoundError";
          }]>;
        };
      };
      409: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ConflictError` - ConflictError
             * @enum {string}
             */
            code: "ConflictError";
          };
        };
      };
      422: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `UnprocessableEntityError` - UnprocessableEntityError
             * @enum {string}
             */
            code: "UnprocessableEntityError";
          };
        };
      };
      429: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `RateLimitError` - RateLimitError
             * @enum {string}
             */
            code: "RateLimitError";
          };
        };
      };
      500: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ProviderInternalServerError` - ProviderInternalServerError
             * @enum {string}
             */
            code: "ProviderInternalServerError";
          } | {
            message: string;
            /**
             * @description * `APIResponseValidationError` - APIResponseValidationError
             * @enum {string}
             */
            code: "APIResponseValidationError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
             * @enum {string}
             */
            code: "ProviderAPIStatusError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
             * @enum {string}
             */
            code: "ProviderAPITimeoutError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
             * @enum {string}
             */
            code: "ProviderAPIConnectionError";
          } | {
            message: string;
            /**
             * @description * `CatchAllError` - CatchAllError
             * @enum {string}
             */
            code: "CatchAllError";
          };
        };
      };
    };
  };
  v1_data_points_list: {
    responses: {
      200: {
        content: {
          "application/json": ({
              id: number;
              /** Format: date-time */
              created_at: string;
              /** Format: date-time */
              updated_at: string;
              input?: string | null;
              output?: string | null;
              positive: boolean;
              /** Format: uuid */
              trace?: string | null;
            })[];
        };
      };
    };
  };
  v1_data_points_create: {
    requestBody: {
      content: {
        "application/json": {
          input?: string | null;
          output?: string | null;
          positive: boolean;
          trace?: string | null;
          project: number;
        };
        "application/x-www-form-urlencoded": {
          input?: string | null;
          output?: string | null;
          positive: boolean;
          trace?: string | null;
          project: number;
        };
        "multipart/form-data": {
          input?: string | null;
          output?: string | null;
          positive: boolean;
          trace?: string | null;
          project: number;
        };
      };
    };
    responses: {
      201: {
        content: {
          "application/json": {
            id: number;
            /** Format: date-time */
            created_at: string;
            /** Format: date-time */
            updated_at: string;
            input?: string | null;
            output?: string | null;
            positive: boolean;
            /** Format: uuid */
            trace?: string | null;
          };
        };
      };
    };
  };
  v1_data_points_retrieve: {
    parameters: {
      path: {
        /** @description A unique integer value identifying this DataPoint. */
        id: number;
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            id: number;
            /** Format: date-time */
            created_at: string;
            /** Format: date-time */
            updated_at: string;
            input?: string | null;
            output?: string | null;
            positive: boolean;
            /** Format: uuid */
            trace?: string | null;
          };
        };
      };
    };
  };
  v1_data_points_update: {
    parameters: {
      path: {
        /** @description A unique integer value identifying this DataPoint. */
        id: number;
      };
    };
    requestBody: {
      content: {
        "application/json": {
          id: number;
          /** Format: date-time */
          created_at: string;
          /** Format: date-time */
          updated_at: string;
          input?: string | null;
          output?: string | null;
          positive: boolean;
          /** Format: uuid */
          trace?: string | null;
        };
        "application/x-www-form-urlencoded": {
          id: number;
          /** Format: date-time */
          created_at: string;
          /** Format: date-time */
          updated_at: string;
          input?: string | null;
          output?: string | null;
          positive: boolean;
          /** Format: uuid */
          trace?: string | null;
        };
        "multipart/form-data": {
          id: number;
          /** Format: date-time */
          created_at: string;
          /** Format: date-time */
          updated_at: string;
          input?: string | null;
          output?: string | null;
          positive: boolean;
          /** Format: uuid */
          trace?: string | null;
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            id: number;
            /** Format: date-time */
            created_at: string;
            /** Format: date-time */
            updated_at: string;
            input?: string | null;
            output?: string | null;
            positive: boolean;
            /** Format: uuid */
            trace?: string | null;
          };
        };
      };
    };
  };
  v1_data_points_destroy: {
    parameters: {
      path: {
        /** @description A unique integer value identifying this DataPoint. */
        id: number;
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            id: number;
            /** Format: date-time */
            created_at: string;
            /** Format: date-time */
            updated_at: string;
            input?: string | null;
            output?: string | null;
            positive: boolean;
            /** Format: uuid */
            trace?: string | null;
          };
        };
      };
    };
  };
  v1_data_points_partial_update: {
    parameters: {
      path: {
        /** @description A unique integer value identifying this DataPoint. */
        id: number;
      };
    };
    requestBody?: {
      content: {
        "application/json": {
          id?: number;
          /** Format: date-time */
          created_at?: string;
          /** Format: date-time */
          updated_at?: string;
          input?: string | null;
          output?: string | null;
          positive?: boolean;
          /** Format: uuid */
          trace?: string | null;
        };
        "application/x-www-form-urlencoded": {
          id?: number;
          /** Format: date-time */
          created_at?: string;
          /** Format: date-time */
          updated_at?: string;
          input?: string | null;
          output?: string | null;
          positive?: boolean;
          /** Format: uuid */
          trace?: string | null;
        };
        "multipart/form-data": {
          id?: number;
          /** Format: date-time */
          created_at?: string;
          /** Format: date-time */
          updated_at?: string;
          input?: string | null;
          output?: string | null;
          positive?: boolean;
          /** Format: uuid */
          trace?: string | null;
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            id: number;
            /** Format: date-time */
            created_at: string;
            /** Format: date-time */
            updated_at: string;
            input?: string | null;
            output?: string | null;
            positive: boolean;
            /** Format: uuid */
            trace?: string | null;
          };
        };
      };
    };
  };
  /** @description Creates embeddings for the given input. */
  v1_embeddings_create: {
    requestBody: {
      content: {
        "application/json": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The model to generate the embeddings. */
          model: string;
          /** @default float */
          encoding_format?: "float" | "base64";
          /** @description Embedding Input */
          input: string | string[] | number[] | number[][];
        };
        "application/x-www-form-urlencoded": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The model to generate the embeddings. */
          model: string;
          /** @default float */
          encoding_format?: "float" | "base64";
          /** @description Embedding Input */
          input: string | string[] | number[] | number[][];
        };
        "multipart/form-data": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description The model to generate the embeddings. */
          model: string;
          /** @default float */
          encoding_format?: "float" | "base64";
          /** @description Embedding Input */
          input: string | string[] | number[] | number[][];
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            /** @description The embeddings for the input. */
            data: {
                /** @description The index of the token in the input. */
                index: number;
                /** @description The embedding for the input. */
                embedding: number[];
              }[];
            /** @description The model to generate the embeddings. */
            model: string;
            /** @description The usage statistics for the completion. */
            usage: {
              prompt_tokens: number;
              completion_tokens?: number;
              total_tokens: number;
            };
            /** @description The name of the provider that generated the completion. */
            provider_name: string;
            /** @description The ID of the provider that generated the completion. */
            provider_id: string;
          };
        };
      };
      400: {
        content: {
          "application/json": {
            /** @description A description of the validation error. */
            message: string;
            /** @description Detailed information about the validation errors. */
            details: {
              [key: string]: {
                /** @description Error messages for the field. */
                error_messages: {
                    [key: string]: unknown;
                  }[];
              };
            };
            /**
             * @description * `ValidationError` - ValidationError
             * @enum {string}
             */
            code: "ValidationError";
          };
        };
      };
      401: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `AuthenticationError` - AuthenticationError
             * @enum {string}
             */
            code: "AuthenticationError";
          };
        };
      };
      403: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `PermissionDeniedError` - PermissionDeniedError
             * @enum {string}
             */
            code: "PermissionDeniedError";
          };
        };
      };
      404: {
        content: {
          "application/json": OneOf<[{
            message: string;
            /**
             * @description * `ProviderNotFoundError` - ProviderNotFoundError
             * @enum {string}
             */
            code: "ProviderNotFoundError";
          }, {
            message: string;
            /**
             * @description * `ModelNotFoundError` - ModelNotFoundError
             * @enum {string}
             */
            code: "ModelNotFoundError";
          }]>;
        };
      };
      409: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ConflictError` - ConflictError
             * @enum {string}
             */
            code: "ConflictError";
          };
        };
      };
      422: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `UnprocessableEntityError` - UnprocessableEntityError
             * @enum {string}
             */
            code: "UnprocessableEntityError";
          };
        };
      };
      429: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `RateLimitError` - RateLimitError
             * @enum {string}
             */
            code: "RateLimitError";
          };
        };
      };
      500: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ProviderInternalServerError` - ProviderInternalServerError
             * @enum {string}
             */
            code: "ProviderInternalServerError";
          } | {
            message: string;
            /**
             * @description * `APIResponseValidationError` - APIResponseValidationError
             * @enum {string}
             */
            code: "APIResponseValidationError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
             * @enum {string}
             */
            code: "ProviderAPIStatusError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
             * @enum {string}
             */
            code: "ProviderAPITimeoutError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
             * @enum {string}
             */
            code: "ProviderAPIConnectionError";
          } | {
            message: string;
            /**
             * @description * `CatchAllError` - CatchAllError
             * @enum {string}
             */
            code: "CatchAllError";
          };
        };
      };
    };
  };
  /** @description Creates a finetuning job. */
  v1_finetuning_create: {
    requestBody: {
      content: {
        "application/json": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description ID of the model to use. See the model endpoint compatibility table for details. */
          model?: string;
          /** @description The training file. */
          training_data: {
              /** @description The input text. */
              input: string;
              /** @description The output text. */
              output: string;
            }[];
          /** @description The training file. */
          validaton_data?: {
              /** @description The input text. */
              input: string;
              /** @description The output text. */
              output: string;
            }[];
          /**
           * @description The number of epochs to train for.
           * @default 1
           */
          num_epochs?: number;
        };
        "application/x-www-form-urlencoded": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description ID of the model to use. See the model endpoint compatibility table for details. */
          model?: string;
          /** @description The training file. */
          training_data: {
              /** @description The input text. */
              input: string;
              /** @description The output text. */
              output: string;
            }[];
          /** @description The training file. */
          validaton_data?: {
              /** @description The input text. */
              input: string;
              /** @description The output text. */
              output: string;
            }[];
          /**
           * @description The number of epochs to train for.
           * @default 1
           */
          num_epochs?: number;
        };
        "multipart/form-data": {
          /** @description The ID of the project to use. */
          project_id: number;
          /** @description ID of the model to use. See the model endpoint compatibility table for details. */
          model?: string;
          /** @description The training file. */
          training_data: {
              /** @description The input text. */
              input: string;
              /** @description The output text. */
              output: string;
            }[];
          /** @description The training file. */
          validaton_data?: {
              /** @description The input text. */
              input: string;
              /** @description The output text. */
              output: string;
            }[];
          /**
           * @description The number of epochs to train for.
           * @default 1
           */
          num_epochs?: number;
        };
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            /** @description The ID of the fine-tuning job. */
            job_id: string;
          };
        };
      };
      400: {
        content: {
          "application/json": {
            /** @description A description of the validation error. */
            message: string;
            /** @description Detailed information about the validation errors. */
            details: {
              [key: string]: {
                /** @description Error messages for the field. */
                error_messages: {
                    [key: string]: unknown;
                  }[];
              };
            };
            /**
             * @description * `ValidationError` - ValidationError
             * @enum {string}
             */
            code: "ValidationError";
          };
        };
      };
      401: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `AuthenticationError` - AuthenticationError
             * @enum {string}
             */
            code: "AuthenticationError";
          };
        };
      };
      403: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `PermissionDeniedError` - PermissionDeniedError
             * @enum {string}
             */
            code: "PermissionDeniedError";
          };
        };
      };
      404: {
        content: {
          "application/json": OneOf<[{
            message: string;
            /**
             * @description * `ProviderNotFoundError` - ProviderNotFoundError
             * @enum {string}
             */
            code: "ProviderNotFoundError";
          }, {
            message: string;
            /**
             * @description * `ModelNotFoundError` - ModelNotFoundError
             * @enum {string}
             */
            code: "ModelNotFoundError";
          }]>;
        };
      };
      409: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ConflictError` - ConflictError
             * @enum {string}
             */
            code: "ConflictError";
          };
        };
      };
      422: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `UnprocessableEntityError` - UnprocessableEntityError
             * @enum {string}
             */
            code: "UnprocessableEntityError";
          };
        };
      };
      429: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `RateLimitError` - RateLimitError
             * @enum {string}
             */
            code: "RateLimitError";
          };
        };
      };
      500: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ProviderInternalServerError` - ProviderInternalServerError
             * @enum {string}
             */
            code: "ProviderInternalServerError";
          } | {
            message: string;
            /**
             * @description * `APIResponseValidationError` - APIResponseValidationError
             * @enum {string}
             */
            code: "APIResponseValidationError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
             * @enum {string}
             */
            code: "ProviderAPIStatusError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
             * @enum {string}
             */
            code: "ProviderAPITimeoutError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
             * @enum {string}
             */
            code: "ProviderAPIConnectionError";
          } | {
            message: string;
            /**
             * @description * `CatchAllError` - CatchAllError
             * @enum {string}
             */
            code: "CatchAllError";
          };
        };
      };
    };
  };
  /** @description Retrieve a finetuning job. */
  v1_finetuning_retrieve: {
    parameters: {
      path: {
        job_id: string;
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            /** @description The ID of the fine-tuning job. */
            id: string;
            /** @description The ID of the fine-tuned model. */
            fine_tuned_model: string;
            /** @description The Unix timestamp (in seconds) of when the fine-tuning job was created. */
            created_at: number;
            /** @description The Unix timestamp (in seconds) of when the fine-tuning job was finished. */
            finished_at?: number;
            /** @description The status of the fine-tuning job. */
            status: string;
            /** @description The error message of the fine-tuning job. */
            error?: string;
            /** @description The name of the provider that generated the completion. */
            provider_name: string;
            /** @description The ID of the provider that generated the completion. */
            provider_id: string;
            /** @description The status code of the fine-tuning job. */
            status_code: number;
          };
        };
      };
      400: {
        content: {
          "application/json": {
            /** @description A description of the validation error. */
            message: string;
            /** @description Detailed information about the validation errors. */
            details: {
              [key: string]: {
                /** @description Error messages for the field. */
                error_messages: {
                    [key: string]: unknown;
                  }[];
              };
            };
            /**
             * @description * `ValidationError` - ValidationError
             * @enum {string}
             */
            code: "ValidationError";
          };
        };
      };
      401: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `AuthenticationError` - AuthenticationError
             * @enum {string}
             */
            code: "AuthenticationError";
          };
        };
      };
      403: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `PermissionDeniedError` - PermissionDeniedError
             * @enum {string}
             */
            code: "PermissionDeniedError";
          };
        };
      };
      404: {
        content: {
          "application/json": OneOf<[{
            message: string;
            /**
             * @description * `ProviderNotFoundError` - ProviderNotFoundError
             * @enum {string}
             */
            code: "ProviderNotFoundError";
          }, {
            message: string;
            /**
             * @description * `ModelNotFoundError` - ModelNotFoundError
             * @enum {string}
             */
            code: "ModelNotFoundError";
          }]>;
        };
      };
      409: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ConflictError` - ConflictError
             * @enum {string}
             */
            code: "ConflictError";
          };
        };
      };
      422: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `UnprocessableEntityError` - UnprocessableEntityError
             * @enum {string}
             */
            code: "UnprocessableEntityError";
          };
        };
      };
      429: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `RateLimitError` - RateLimitError
             * @enum {string}
             */
            code: "RateLimitError";
          };
        };
      };
      500: {
        content: {
          "application/json": {
            message: string;
            /**
             * @description * `ProviderInternalServerError` - ProviderInternalServerError
             * @enum {string}
             */
            code: "ProviderInternalServerError";
          } | {
            message: string;
            /**
             * @description * `APIResponseValidationError` - APIResponseValidationError
             * @enum {string}
             */
            code: "APIResponseValidationError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIStatusError` - ProviderAPIStatusError
             * @enum {string}
             */
            code: "ProviderAPIStatusError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPITimeoutError` - ProviderAPITimeoutError
             * @enum {string}
             */
            code: "ProviderAPITimeoutError";
          } | {
            message: string;
            /**
             * @description * `ProviderAPIConnectionError` - ProviderAPIConnectionError
             * @enum {string}
             */
            code: "ProviderAPIConnectionError";
          } | {
            message: string;
            /**
             * @description * `CatchAllError` - CatchAllError
             * @enum {string}
             */
            code: "CatchAllError";
          };
        };
      };
    };
  };
  v1_models_list: {
    responses: {
      200: {
        content: {
          "application/json": ({
              id: number;
              name: string;
              /**
               * @description * `text2text` - Text to Text
               * * `text2image` - Text to Image
               * * `text2vector` - Text to Vector
               * @enum {string}
               */
              model_type?: "text2text" | "text2image" | "text2vector";
              model_provider?: ("openai" | "azure" | "azure-mistral" | "cohere" | "anthropic" | "cloudflare" | "deepinfra" | "lamini" | "octoai" | "replicate" | "together" | "fireworksai" | "mistralai" | "prem" | "anyscale" | "openrouter" | "perplexity" | "groq") | "" | null;
            })[];
        };
      };
    };
  };
  v1_models_retrieve: {
    parameters: {
      path: {
        /** @description A unique integer value identifying this Model. */
        id: number;
      };
    };
    responses: {
      200: {
        content: {
          "application/json": {
            id: number;
            name: string;
            /**
             * @description * `text2text` - Text to Text
             * * `text2image` - Text to Image
             * * `text2vector` - Text to Vector
             * @enum {string}
             */
            model_type?: "text2text" | "text2image" | "text2vector";
            model_provider?: ("openai" | "azure" | "azure-mistral" | "cohere" | "anthropic" | "cloudflare" | "deepinfra" | "lamini" | "octoai" | "replicate" | "together" | "fireworksai" | "mistralai" | "prem" | "anyscale" | "openrouter" | "perplexity" | "groq") | "" | null;
          };
        };
      };
    };
  };
  v1_repository_document_create: {
    parameters: {
      path: {
        repository_id: number;
      };
    };
    requestBody: {
      content: {
        "application/json": {
          name: string;
          content: string;
          /**
           * @description * `pdf` - PDF
           * * `docx` - Word
           * * `txt` - Text
           * @enum {string}
           */
          document_type: "pdf" | "docx" | "txt";
        };
        "application/x-www-form-urlencoded": {
          name: string;
          content: string;
          /**
           * @description * `pdf` - PDF
           * * `docx` - Word
           * * `txt` - Text
           * @enum {string}
           */
          document_type: "pdf" | "docx" | "txt";
        };
        "multipart/form-data": {
          name: string;
          content: string;
          /**
           * @description * `pdf` - PDF
           * * `docx` - Word
           * * `txt` - Text
           * @enum {string}
           */
          document_type: "pdf" | "docx" | "txt";
        };
      };
    };
    responses: {
      201: {
        content: {
          "application/json": {
            repository_id: number;
            document_id: number;
            name: string;
            /**
             * @description * `pdf` - PDF
             * * `docx` - Word
             * * `txt` - Text
             * @enum {string}
             */
            document_type: "pdf" | "docx" | "txt";
            /**
             * @description * `PENDING` - Pending
             * * `UPLOADED` - Uploaded
             * * `PARSING` - Parsing
             * * `CHUNKING` - Chunking
             * * `WAITING_FOR_CHUNKS_COMPLETION` - Waiting for chunks completion
             * * `PROCESSING` - Processing
             * * `COMPLETED` - Completed
             * * `FAILED` - Failed
             * @enum {string}
             */
            status: "PENDING" | "UPLOADED" | "PARSING" | "CHUNKING" | "WAITING_FOR_CHUNKS_COMPLETION" | "PROCESSING" | "COMPLETED" | "FAILED";
            error: string | null;
            /** @default 0 */
            chunk_count: number;
          };
        };
      };
    };
  };
}
